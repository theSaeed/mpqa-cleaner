{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d_XrB849SNBz",
      "metadata": {
        "id": "d_XrB849SNBz"
      },
      "outputs": [],
      "source": [
        "# Doclists\n",
        "\n",
        "ULA_SUBSET_DOCS = ['ula/119CWL041', 'ula/RindnerBonnie', 'ula/HistoryGreek', 'ula/Article247_3500', 'ula/NapierDianne', 'ula/sw2071-UTF16-ms98-a-trans', 'ula/118CWL050', 'ula/114CUL059', 'ula/110CYL067', 'ula/PolkMaria', 'ula/116CUL034', 'ula/115CVL037', 'ula/118CWL049', 'ula/Article247_66', 'ula/110CYL068', 'ula/113CWL017', 'ula/112C-L015', 'ula/115CVL036', 'ula/115CVL035', 'ula/Article247_328', 'ula/114CUL060', 'ula/112C-L012', 'ula/118CWL048', 'ula/ReidSandra', 'ula/112C-L016', 'ula/HistoryJerusalem', 'ula/110CYL070', 'ula/sw2014-UTF16-ms98-a-trans', 'ula/112C-L014', 'ula/117CWL008', 'ula/sw2078-UTF16-ms98-a-trans', 'ula/110CYL071', 'ula/114CUL057', 'ula/116CUL032', 'ula/110CYL069', 'ula/117CWL009', 'ula/110CYL072', 'ula/chapter-10', 'ula/116CUL033', 'ula/ch5', 'ula/sw2015-ms98-a-trans', 'ula/113CWL018', 'ula/110CYL200', 'ula/Article247_327', 'ula/114CUL058', 'ula/112C-L013', 'ula/Article247_500', 'ula/Article247_400']\n",
        "ULA_LU_SUBSET_DOCS = ['ula/A1.E2-NEW', 'ula/wsj_1640.mrg-NEW', 'ula/AFGP-2002-600045-Trans', 'ula/20000410_nyt-NEW', 'ula/20000415_apw_eng-NEW', 'ula/AFGP-2002-602187-Trans', 'ula/20000815_AFP_ARB.0084.IBM-HA-NEW', 'ula/CNN_AARONBROWN_ENG_20051101_215800.partial-NEW', 'ula/20000424_nyt-NEW', 'ula/20000419_apw_eng-NEW', 'ula/20000416_xin_eng-NEW', 'ula/enron-thread-159550', 'ula/wsj_2465', 'ula/AFGP-2002-600002-Trans', 'ula/ENRON-pearson-email-25jul02', 'ula/im_401b_e73i32c22_031705-2', 'ula/A1.E1-NEW', 'ula/CNN_ENG_20030614_173123.4-NEW-1', 'ula/20000420_xin_eng-NEW', 'ula/IZ-060316-01-Trans-1', 'ula/sw2025-ms98-a-trans.ascii-1-NEW', 'ula/SNO-525', 'ula/AFGP-2002-600175-Trans', 'ula/602CZL285-1']\n",
        "XBANK_DOCS = ['xbank/wsj_0904', 'xbank/wsj_0760', 'xbank/wsj_0713', 'xbank/wsj_0709', 'xbank/wsj_0706', 'xbank/wsj_0662', 'xbank/wsj_0558', 'xbank/wsj_0555', 'xbank/wsj_0551', 'xbank/wsj_0542', 'xbank/wsj_0541', 'xbank/wsj_0332', 'xbank/wsj_0292', 'xbank/wsj_0189', 'xbank/wsj_0316', 'xbank/wsj_0175', 'xbank/wsj_0321', 'xbank/wsj_0176', 'xbank/wsj_0173', 'xbank/wsj_0026', 'xbank/wsj_0324', 'xbank/wsj_0187', 'xbank/wsj_0356', 'xbank/wsj_0325', 'xbank/wsj_0340', 'xbank/wsj_0679', 'xbank/wsj_0695', 'xbank/wsj_0661', 'xbank/wsj_0570', 'xbank/wsj_0557', 'xbank/wsj_0751', 'xbank/wsj_0805', 'xbank/wsj_0762', 'xbank/wsj_0736', 'xbank/wsj_0806', 'xbank/wsj_1040', 'xbank/wsj_1039', 'xbank/wsj_1042', 'xbank/wsj_0568', 'xbank/wsj_0778', 'xbank/wsj_0160', 'xbank/wsj_0136', 'xbank/wsj_0135', 'xbank/wsj_0127', 'xbank/wsj_0122', 'xbank/wsj_0032', 'xbank/wsj_0150', 'xbank/wsj_0165', 'xbank/wsj_0157', 'xbank/wsj_0151', 'xbank/wsj_0685', 'xbank/wsj_0168', 'xbank/wsj_0167', 'xbank/wsj_0161', 'xbank/wsj_0152', 'xbank/wsj_0073', 'xbank/wsj_0068', 'xbank/wsj_0171', 'xbank/wsj_0144', 'xbank/wsj_0991', 'xbank/wsj_0923', 'xbank/wsj_0907', 'xbank/wsj_0811', 'xbank/wsj_0667', 'xbank/wsj_0534', 'xbank/wsj_0924', 'xbank/wsj_0815', 'xbank/wsj_1038', 'xbank/wsj_1035', 'xbank/wsj_1033', 'xbank/wsj_0527', 'xbank/wsj_0928', 'xbank/wsj_0973', 'xbank/wsj_0950', 'xbank/wsj_0927', 'xbank/wsj_0376', 'xbank/wsj_0660', 'xbank/wsj_0650', 'xbank/wsj_0266', 'xbank/wsj_0006', 'xbank/wsj_0768', 'xbank/wsj_1073', 'xbank/wsj_0816', 'xbank/wsj_0610', 'xbank/wsj_0583']\n",
        "INPUT_FORMATS = {\n",
        "    'T|A|S': [\"T:A|S\", \"T:S|A\", \"T|A|S\", \"T|S|A\", \"A|S|T\", \"S|A|T\", \"T:T|A:A|S:S\", \"T:T|S:S|A:A\", \"A:A|S:S|T:T\", \"S:S|A:A|T:T\", \"T=T|A=A|S=S\", \"T=T|S=S|A=A\", \"A=A|S=S|T=T\", \"S=S|A=A|T=T\"],\n",
        "    'A|S': [\"A|S\", \"S|A\", \"A:A|S:S\", \"A=A|S=S\", \"S:S|A:A\", \"S=S|A=A\"],\n",
        "    'S': [\"S\"],\n",
        "    'A': [\"A\"],\n",
        "}\n",
        "OUTPUT_FORMATS = {\n",
        "    't': ['t', 't(ordered)'],\n",
        "    'p': ['p'],\n",
        "    'i': ['i'],\n",
        "    't|p|i:': ['t|p|i', 't|p|I:i', 't|P:p|i', 't|P:p|I:i', 'T:t|p|i', 'T:t|p|I:i', 'T:t|P:p|i', 'T:t|P:p|I:i'],\n",
        "    't,p,i:': ['t,p,i', 't,p,I:i', 't,P:p,i', 't,P:p,I:i', 'T:t,p,i', 'T:t,p,I:i', 'T:t,P:p,i', 'T:t,P:p,I:i'],\n",
        "    't|p|i=': ['t|p|i', 't|p|I=i', 't|P=p|i', 't|P=p|I=i', 'T=t|p|i', 'T=t|p|I=i', 'T=t|P=p|i', 'T=t|P=p|I=i'],\n",
        "    't,p,i=': ['t,p,i', 't,p,I=i', 't,P=p,i', 't,P=p,I=i', 'T=t,p,i', 'T=t,p,I=i', 'T=t,P=p,i', 'T=t,P=p,I=i'],\n",
        "}\n",
        "\n",
        "################################################################################\n",
        "\n",
        "#@title Parameters\n",
        "\n",
        "EXPERIMENT_NAME = 't5'\n",
        "IGNORED_DOCS = ULA_SUBSET_DOCS + ULA_LU_SUBSET_DOCS + XBANK_DOCS # e.g. set it to ['non_fbis/06.11.16-17420'] to remove all objects with that specific document id\n",
        "MODEL_NAME = 'google/flan-t5-base' #@param [\"t5-small\", \"t5-base\", \"t5-large\", \"google/flan-t5-small\", \"google/flan-t5-base\", \"google/flan-t5-large\"]\n",
        "INPUT_FORMAT = 'A|S' #@param [\"T:A|S\", \"T:S|A\", \"T|A|S\", \"T|S|A\", \"A|S|T\", \"S|A|T\", \"T:T|A:A|S:S\", \"T:T|S:S|A:A\", \"A:A|S:S|T:T\", \"S:S|A:A|T:T\", \"T=T|A=A|S=S\", \"T=T|S=S|A=A\", \"A=A|S=S|T=T\", \"S=S|A=A|T=T\", \"A|S\", \"S|A\", \"A:A|S:S\", \"A=A|S=S\", \"S:S|A:A\", \"S=S|A=A\", \"S\", \"A\"]\n",
        "REMOVE_PIPES_FROM_INPUT = False\n",
        "OUTPUT_FORMAT = 't,p,i' #@param ['t', 't(ordered)', 'p', 'i', 't|p|i', 't|p|I:i', 't|P:p|i', 't|P:p|I:i', 'T:t|p|i', 'T:t|p|I:i', 'T:t|P:p|i', 'T:t|P:p|I:i', 't,p,i', 't,p,I:i', 't,P:p,i', 't,P:p,I:i', 'T:t,p,i', 'T:t,p,I:i', 'T:t,P:p,i', 'T:t,P:p,I:i', 't|p|i', 't|p|I=i', 't|P=p|i', 't|P=p|I=i', 'T=t|p|i', 'T=t|p|I=i', 'T=t|P=p|i', 'T=t|P=p|I=i', 't,p,i', 't,p,I=i', 't,P=p,i', 't,P=p,I=i', 'T=t,p,i', 'T=t,p,I=i', 'T=t,P=p,i', 'T=t,P=p,I=i']\n",
        "ADD_TASK_PREFIX = False #@param {type: 'boolean'}\n",
        "CUSTOM_PREFIX = '' #@param {type: 'string'}\n",
        "TEXT_KEY = 'clean_text' #@param [\"text\", \"clean_text\", \"w_text\"]\n",
        "HEAD_KEY = 'clean_head' #@param [\"head\", \"clean_head\", \"w_head\"]\n",
        "FREEZE_ENCODER_LAYER_COUNT = -1 #@param {type: \"slider\", min: -1, max: 13}\n",
        "FREEZE_DECODER_LAYER_COUNT = -1 #@param {type: \"slider\", min: -1, max: 13}\n",
        "LEARNING_RATE = 1e-4 #@param {\"type\": \"number\"}\n",
        "CAPITALIZATION_NORMALIZATION = True #@param {type: 'boolean'}\n",
        "FP16 = False\n",
        "LOCAL_RANK = -1\n",
        "FP16_OPT_LEVEL = 'O1'\n",
        "PER_DEVICE_TRAIN_BATCH_SIZE = 16 #@param {type: \"integer\"}\n",
        "PER_DEVICE_VAL_BATCH_SIZE = 64 #@param {type: \"integer\"}\n",
        "PER_DEVICE_TEST_BATCH_SIZE = 1\n",
        "LOGGING_STEPS = 400 #@param {\"type\": \"integer\"}\n",
        "EVAL_STRATEGY = 'steps'\n",
        "SAVE_STRATEGY = 'steps'\n",
        "LOAD_BEST_MODEL_AT_END = True\n",
        "METRIC_FOR_BEST_MODEL = 'eval_average_of_metrics'\n",
        "DROPOUT = 0.1\n",
        "NUM_TRAIN_EPOCHS = 20\n",
        "EARLY_STOPPING = 3 # Set 0 to disable\n",
        "SEED = 0\n",
        "MAX_FOLDS = 5 #@param {\"type\": \"integer\"}\n",
        "# Stop the iterartion after MAX_FOLDS folds.\n",
        "SHOW_WRONG_PREDICTIONS = True #@param {\"type\": \"boolean\"}\n",
        "PREDICT_WITH_GENERATE = True #@param {type:\"boolean\"}\n",
        "STORE_RESULTS = [] # Array of metrics' names: save and store results of a suite of notebooks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dJOkpC4OEnku",
      "metadata": {
        "id": "dJOkpC4OEnku"
      },
      "outputs": [],
      "source": [
        "# Dataset\n",
        "FETCH_DATASET_FROM_WEB = True # Set it to true, to download the dataset online\n",
        "SPLITS_URL = 'https://raw.githubusercontent.com/theSaeed/opinion-mining-using-llms/master/dataset/folds/tpi-folds.json'\n",
        "\n",
        "DATA_URL = '[replace dataset link here]' # WEB\n",
        "# OR\n",
        "FILE_ADDRESS = 'dataset/MPQA2.0_cleaned.json' # LOCAL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KQgSEbjZoaPX",
      "metadata": {
        "id": "KQgSEbjZoaPX"
      },
      "outputs": [],
      "source": [
        "!pwd\n",
        "%mkdir models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_SF7ZRNPzG1m",
      "metadata": {
        "id": "_SF7ZRNPzG1m"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce192a0a-9703-4393-ab55-c24cdd1222cc",
      "metadata": {
        "id": "ce192a0a-9703-4393-ab55-c24cdd1222cc"
      },
      "outputs": [],
      "source": [
        "# Libraries Required for Google Colab\n",
        "\n",
        "# %pip install transformers[sentencepiece]==4.25.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xyDbVHftZ0it",
      "metadata": {
        "id": "xyDbVHftZ0it"
      },
      "outputs": [],
      "source": [
        "# To assure deterministic results\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96f96831-ae2c-4adc-8730-cc07b9b5ba74",
      "metadata": {
        "id": "96f96831-ae2c-4adc-8730-cc07b9b5ba74"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import sys\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq, EarlyStoppingCallback, AutoConfig\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, multilabel_confusion_matrix\n",
        "import json\n",
        "from urllib.request import urlopen\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import statistics\n",
        "from datetime import datetime\n",
        "import logging\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WHtALgYKZzhP",
      "metadata": {
        "id": "WHtALgYKZzhP"
      },
      "outputs": [],
      "source": [
        "# Start timer\n",
        "\n",
        "start_time = datetime.now()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d2ab8c6-603d-40af-875b-5b6f68f9accc",
      "metadata": {
        "id": "2d2ab8c6-603d-40af-875b-5b6f68f9accc"
      },
      "outputs": [],
      "source": [
        "# Setup device\n",
        "\n",
        "device_string = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device_hf = 0 if torch.cuda.is_available() else -1\n",
        "device = torch.device(device_string)\n",
        "print(\"Device:\", device)\n",
        "NUM_WORKERS = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ntWz_6EbfJG2",
      "metadata": {
        "id": "ntWz_6EbfJG2"
      },
      "outputs": [],
      "source": [
        "FOLDS = [\n",
        "    ['IDs_trainset_fold_1', 'IDs_validationset_fold_1', 'IDs_testset_fold_1'],\n",
        "    ['IDs_trainset_fold_2', 'IDs_validationset_fold_2', 'IDs_testset_fold_2'],\n",
        "    ['IDs_trainset_fold_3', 'IDs_validationset_fold_3', 'IDs_testset_fold_3'],\n",
        "    ['IDs_trainset_fold_4', 'IDs_validationset_fold_4', 'IDs_testset_fold_4'],\n",
        "    ['IDs_trainset_fold_5', 'IDs_validationset_fold_5', 'IDs_testset_fold_5'],\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rPg43SUKxudA",
      "metadata": {
        "id": "rPg43SUKxudA"
      },
      "outputs": [],
      "source": [
        "# Classes\n",
        "\n",
        "TYPE_CLASSES = ['agreement', 'arguing', 'expressive_subjectivity', 'intention', 'sentiment']\n",
        "POLARITY_CLASSES = ['negative', 'neutral', 'positive']\n",
        "INTENSITY_CLASSES = ['low', 'low-medium', 'medium', 'medium-high', 'high', 'high-extreme', 'extreme']\n",
        "POLARITY_DICT = {'negative': [1, 0, 0], 'neutral': [0, 1, 0], 'positive': [0, 0, 1]}\n",
        "INTENSITY_DICT = {'low': [1, 0, 0], 'low-medium': [1, 1, 0], 'medium': [0, 1, 0], 'medium-high': [0, 1, 1], 'high': [0, 0, 1], 'high-extreme': [0, 0, 1], 'extreme': [0, 0, 1]}\n",
        "NUM_TYPE_CLASSES = len(TYPE_CLASSES)\n",
        "NUM_POLARITY_CLASSES = len(POLARITY_CLASSES)\n",
        "NUM_INTENSITY_CLASSES = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "856a085e-a728-4a8e-8f75-193820216f52",
      "metadata": {
        "id": "856a085e-a728-4a8e-8f75-193820216f52"
      },
      "outputs": [],
      "source": [
        "# Callbacks\n",
        "\n",
        "CALLBACKS = []\n",
        "if EARLY_STOPPING > 0:\n",
        "    CALLBACKS.append(EarlyStoppingCallback(EARLY_STOPPING))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6a21171-f03f-45d1-9293-4bcb4183eb02",
      "metadata": {
        "id": "b6a21171-f03f-45d1-9293-4bcb4183eb02"
      },
      "outputs": [],
      "source": [
        "def set_seed():\n",
        "    random.seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65615ad0-5c82-4079-be75-122e75d8441c",
      "metadata": {
        "id": "65615ad0-5c82-4079-be75-122e75d8441c"
      },
      "source": [
        "# Preparing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28384faa-36ff-4caa-b598-4946d990c7ba",
      "metadata": {
        "id": "28384faa-36ff-4caa-b598-4946d990c7ba"
      },
      "outputs": [],
      "source": [
        "# Fetch the dataset\n",
        "\n",
        "if FETCH_DATASET_FROM_WEB:\n",
        "    response = urlopen(DATA_URL)\n",
        "    csds_collection = json.loads(response.read())\n",
        "    response = urlopen(SPLITS_URL)\n",
        "    csds_splits = json.loads(response.read())\n",
        "else:\n",
        "    with open(FILE_ADDRESS) as file:\n",
        "        csds_collection = json.load(file)\n",
        "    response = urlopen(SPLITS_URL)\n",
        "    csds_splits = json.loads(response.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "seHNkX9zWuDF",
      "metadata": {
        "id": "seHNkX9zWuDF"
      },
      "outputs": [],
      "source": [
        "# Create a map for class ids and class names\n",
        "\n",
        "type_classname2classindex = {\n",
        "    'agreement':               0,\n",
        "    'arguing':                 1,\n",
        "    'expressive_subjectivity': 2,\n",
        "    'intention':               3,\n",
        "    'sentiment':               4\n",
        "}\n",
        "type_classname2classid = {\n",
        "    'agreement':               'agreement',\n",
        "    'arguing':                 'arguing',\n",
        "    'expressive_subjectivity': 'expressive',\n",
        "    'intention':               'intention',\n",
        "    'sentiment':               'sentiment'\n",
        "}\n",
        "type_classid2classname = {v:k for k, v in type_classname2classid.items()}\n",
        "type_classid2classindex = {type_classname2classid[k]:v for k, v in type_classname2classindex.items()}\n",
        "\n",
        "polarity_classname2classindex = {\n",
        "    'negative': 0,\n",
        "    'neutral':  1,\n",
        "    'positive': 2,\n",
        "}\n",
        "polarity_classname2classid = {\n",
        "    'negative': 'negative',\n",
        "    'neutral':  'neutral',\n",
        "    'positive': 'positive'\n",
        "}\n",
        "polarity_classid2classname = {v:k for k, v in polarity_classname2classid.items()}\n",
        "polarity_classid2classindex = {polarity_classname2classid[k]:v for k, v in polarity_classname2classindex.items()}\n",
        "\n",
        "intensity_classname2classindex = {\n",
        "    'low':    0,\n",
        "    'medium': 1,\n",
        "    'high':   2,\n",
        "}\n",
        "intensity_classname2classid = {\n",
        "    'low': 'low',\n",
        "    'low-medium': 'low medium',\n",
        "    'medium': 'medium',\n",
        "    'medium-high': 'medium high',\n",
        "    'high': 'high',\n",
        "    'high-extreme': 'high',\n",
        "    'extreme': 'high'\n",
        "}\n",
        "intensity_classid2classname = {v:k for k, v in intensity_classname2classid.items()}\n",
        "intensity_classid2classindex = {intensity_classname2classid[k]:v for k, v in intensity_classname2classindex.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Cao9699HZUIb",
      "metadata": {
        "id": "Cao9699HZUIb"
      },
      "outputs": [],
      "source": [
        "# Convert binary arrays to a decimal numbers and vice versa\n",
        "\n",
        "def bin2dec(bin_arrays):\n",
        "    result = []\n",
        "    for arr in bin_arrays:\n",
        "        result += [0]\n",
        "        for i in reversed(arr):\n",
        "            result[-1] *= 2\n",
        "            if i == 1:\n",
        "               result[-1] += 1\n",
        "    return result\n",
        "\n",
        "def dec2bin(arr):\n",
        "    result = []\n",
        "    for i in arr:\n",
        "        result += [[0] * NUM_TYPE_CLASSES]\n",
        "        for j in range(NUM_TYPE_CLASSES):\n",
        "            if i % 2 == 1:\n",
        "                result[-1][j] = 1\n",
        "            i //= 2\n",
        "    return result\n",
        "\n",
        "# Use first class in each sample for stratifying (Experimental)\n",
        "def bin_stratify_indicator(bin_arrays):\n",
        "    result = []\n",
        "    for arr in bin_arrays:\n",
        "        for i in range(len(arr)):\n",
        "            if arr[i] == 1:\n",
        "                result += [i]\n",
        "                break\n",
        "    return result\n",
        "\n",
        "def dec_stratify_indicator(dec_arr):\n",
        "    result = []\n",
        "    for i in dec_arr:\n",
        "        for j in range(NUM_TYPE_CLASSES):\n",
        "            if i % 2 == 1:\n",
        "                result += [j]\n",
        "                break\n",
        "            i //= 2\n",
        "    return result\n",
        "\n",
        "example = [[1, 0, 0, 0, 0], [0, 1, 1, 1, 1], [0, 0, 1, 1, 0]]\n",
        "print('Example:', example)\n",
        "print('bin2dec:', bin2dec(example))\n",
        "print('dec2bin(bin2dec):', dec2bin(bin2dec(example)))\n",
        "print('bin_stratify_indicator:', bin_stratify_indicator(example))\n",
        "print('dec_stratify_indicator:', dec_stratify_indicator(bin2dec(example)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WdjplMGJj_ld",
      "metadata": {
        "id": "WdjplMGJj_ld"
      },
      "outputs": [],
      "source": [
        "# Keep the objects with the specified ids\n",
        "\n",
        "def filter_csds_objects(csds_objects, subset_ids):\n",
        "    subset_ids_set = set(subset_ids)\n",
        "    return [\n",
        "        csds_object for csds_object in csds_objects if csds_object['unique_id'] in subset_ids_set\n",
        "    ]\n",
        "\n",
        "def filter_csds_objects_all(csds_objects, train_ids, val_ids, test_ids):\n",
        "    train_ids_set = set(train_ids)\n",
        "    val_ids_set = set(val_ids)\n",
        "    test_ids_set = set(test_ids)\n",
        "\n",
        "    train_objects, val_objects, test_objects = [], [], []\n",
        "\n",
        "    for csds_object in csds_objects:\n",
        "        if csds_object['unique_id'] in val_ids_set:\n",
        "            val_objects.append(csds_object)\n",
        "        elif csds_object['unique_id'] in test_ids_set:\n",
        "            test_objects.append(csds_object)\n",
        "        elif csds_object['unique_id'] in train_ids_set:\n",
        "            train_objects.append(csds_object)\n",
        "\n",
        "    return train_objects, val_objects, test_objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "t1C420sSPbw1",
      "metadata": {
        "id": "t1C420sSPbw1"
      },
      "outputs": [],
      "source": [
        "def generate_text_cognitive_state(output_format, annotype_id, polarity_id, intensity_id):\n",
        "    output = ''\n",
        "\n",
        "    inner_seperator = ''\n",
        "    if ':' in output_format:\n",
        "        inner_seperator = ' : '\n",
        "    elif '=' in output_format:\n",
        "        inner_seperator = ' = '\n",
        "\n",
        "    outer_seperator = ''\n",
        "    if '|' in output_format:\n",
        "        outer_seperator = ' | '\n",
        "    elif ',' in output_format:\n",
        "        outer_seperator = ' , '\n",
        "\n",
        "    if 'T' in output_format:\n",
        "        output += 'type' + inner_seperator\n",
        "    output += annotype_id + outer_seperator\n",
        "\n",
        "    if 'P' in output_format:\n",
        "        output += 'polarity' + inner_seperator\n",
        "    output += polarity_id + outer_seperator\n",
        "\n",
        "    if 'I' in output_format:\n",
        "        output += 'intensity' + inner_seperator\n",
        "    output += intensity_id\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qgZfNCd9Qb4H",
      "metadata": {
        "id": "qgZfNCd9Qb4H"
      },
      "outputs": [],
      "source": [
        "# Preparing inputs and targets\n",
        "\n",
        "def prepare_inputs_and_targets(csds_objects):\n",
        "\n",
        "    input_output_dict = {}\n",
        "    n_samples = 0\n",
        "\n",
        "    for csds_object in csds_objects:\n",
        "        doc_id = csds_object['doc_id']\n",
        "        unique_id = csds_object['unique_id']\n",
        "        text = csds_object[TEXT_KEY]\n",
        "        head = csds_object[HEAD_KEY]\n",
        "        annotype  = csds_object['annotation_type']\n",
        "        polarity  = csds_object['polarity']\n",
        "        intensity = csds_object['intensity']\n",
        "\n",
        "        if   INPUT_FORMAT in INPUT_FORMATS['T|A|S']:\n",
        "            key = (annotype, head, text)\n",
        "        elif INPUT_FORMAT in INPUT_FORMATS['A|S']:\n",
        "            key = (head, text)\n",
        "        elif INPUT_FORMAT in INPUT_FORMATS['A']:\n",
        "            key = (head,)\n",
        "        elif INPUT_FORMAT in INPUT_FORMATS['S']:\n",
        "            key = (text,)\n",
        "        else:\n",
        "            print(\"INPUT FORMAT NOT SUPPORTED IN prepare_inputs_and_targets\")\n",
        "\n",
        "        if annotype in TYPE_CLASSES and polarity in POLARITY_CLASSES and intensity in INTENSITY_CLASSES \\\n",
        "            and doc_id not in IGNORED_DOCS:\n",
        "\n",
        "            annotype_id  = type_classname2classid[annotype]\n",
        "            polarity_id  = polarity_classname2classid[polarity]\n",
        "            intensity_id = intensity_classname2classid[intensity]\n",
        "\n",
        "            if key not in input_output_dict:\n",
        "                if   OUTPUT_FORMAT in ['t', 'p', 'i'] + OUTPUT_FORMATS['t|p|i:'] + OUTPUT_FORMATS['t,p,i:'] + OUTPUT_FORMATS['t|p|i='] + OUTPUT_FORMATS['t,p,i=']:\n",
        "                    input_output_dict[key] = ''\n",
        "                elif OUTPUT_FORMAT in ['t(ordered)']:\n",
        "                    input_output_dict[key] = set()\n",
        "                else:\n",
        "                    print(\"OUTPUT FORMAT NOT SUPPORTED IN prepare_inputs_and_targets\")\n",
        "                n_samples += 1\n",
        "            else:\n",
        "                if   OUTPUT_FORMAT in ['t', 'p', 'i']:\n",
        "                    input_output_dict[key] += ' '\n",
        "                elif OUTPUT_FORMAT in ['t(ordered)']:\n",
        "                    None\n",
        "                elif OUTPUT_FORMAT in OUTPUT_FORMATS['t|p|i:'] + OUTPUT_FORMATS['t|p|i=']:\n",
        "                    input_output_dict[key] += ' || '\n",
        "                elif OUTPUT_FORMAT in OUTPUT_FORMATS['t,p,i:'] + OUTPUT_FORMATS['t,p,i=']:\n",
        "                    input_output_dict[key] += ' | '\n",
        "                else:\n",
        "                    print(\"OUTPUT FORMAT NOT SUPPORTED IN prepare_inputs_and_targets\")\n",
        "\n",
        "            if   OUTPUT_FORMAT in ['t']:\n",
        "                input_output_dict[key] += annotype_id\n",
        "            elif OUTPUT_FORMAT in ['t(ordered)']:\n",
        "                input_output_dict[key].add(annotype_id)\n",
        "            elif OUTPUT_FORMAT in ['p']:\n",
        "                input_output_dict[key] += polarity_id\n",
        "            elif OUTPUT_FORMAT in ['i']:\n",
        "                input_output_dict[key] += intensity_id\n",
        "            elif OUTPUT_FORMAT in OUTPUT_FORMATS['t|p|i:'] + OUTPUT_FORMATS['t,p,i:'] + OUTPUT_FORMATS['t|p|i='] + OUTPUT_FORMATS['t,p,i=']:\n",
        "                input_output_dict[key] += generate_text_cognitive_state(OUTPUT_FORMAT, annotype_id, polarity_id, intensity_id)\n",
        "            else:\n",
        "                print(\"OUTPUT FORMAT NOT SUPPORTED IN prepare_inputs_and_targets\")\n",
        "\n",
        "    if OUTPUT_FORMAT in ['t(ordered)']:\n",
        "        for k in input_output_dict.keys():\n",
        "            v = input_output_dict[k]\n",
        "            list_v = list(v)\n",
        "            text_v = list_v[0]\n",
        "            for i in range(1, len(list_v)):\n",
        "                text_v = text_v + ' ' + list_v[i]\n",
        "            input_output_dict[k] = text_v\n",
        "\n",
        "    return input_output_dict, n_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee725191-73e1-47ee-a8d6-1465aa32b6f4",
      "metadata": {
        "id": "ee725191-73e1-47ee-a8d6-1465aa32b6f4"
      },
      "outputs": [],
      "source": [
        "# All samples\n",
        "\n",
        "csds_objects = csds_collection['csds_objects']\n",
        "\n",
        "train_val_test_objects = filter_csds_objects(csds_objects, csds_splits[FOLDS[0][0]]) + \\\n",
        "                         filter_csds_objects(csds_objects, csds_splits[FOLDS[0][1]]) + \\\n",
        "                         filter_csds_objects(csds_objects, csds_splits[FOLDS[0][2]])\n",
        "input_target_dict, n_samples = prepare_inputs_and_targets(train_val_test_objects)\n",
        "\n",
        "i = 2 # (i+1)-th sample\n",
        "print(f'inputs and targets for {i+1}-th csds object (out of {n_samples}):')\n",
        "print(f'input_output_dict.items()[{i}]:', list(input_target_dict.items())[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CaRqDRcglTSR",
      "metadata": {
        "id": "CaRqDRcglTSR"
      },
      "outputs": [],
      "source": [
        "# Prepare X and y\n",
        "\n",
        "X = list(input_target_dict.keys())\n",
        "y = list(input_target_dict.values())\n",
        "\n",
        "print(X[-3:])\n",
        "print(y[-3:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SlaL_2Zxkbzr",
      "metadata": {
        "id": "SlaL_2Zxkbzr"
      },
      "outputs": [],
      "source": [
        "X = np.array(X)\n",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37ab1607-bad3-4222-b15c-0ac3ec39acd5",
      "metadata": {
        "id": "37ab1607-bad3-4222-b15c-0ac3ec39acd5"
      },
      "source": [
        "# Preparing the model and torch dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b732e3ad-d4f0-4ee5-8d6c-0bdc523539f8",
      "metadata": {
        "id": "b732e3ad-d4f0-4ee5-8d6c-0bdc523539f8"
      },
      "outputs": [],
      "source": [
        "# Load the hf model and tokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, model_max_length=512)\n",
        "def load_model_hf():\n",
        "    model_hf = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "        MODEL_NAME, resume_download=True,\n",
        "        config=AutoConfig.from_pretrained(MODEL_NAME)\n",
        "    )\n",
        "\n",
        "    if FREEZE_ENCODER_LAYER_COUNT > -1:\n",
        "        # We freeze the embeddings of the model here\n",
        "        for param in model_hf.shared.parameters():\n",
        "            param.requires_grad = False\n",
        "        if FREEZE_ENCODER_LAYER_COUNT != 0:\n",
        "            for layer in model_hf.encoder.block[:min(12, FREEZE_ENCODER_LAYER_COUNT)]:\n",
        "                for param in layer.parameters():\n",
        "                    param.requires_grad = False\n",
        "        if FREEZE_ENCODER_LAYER_COUNT == len(model_hf.encoder.block)+1:\n",
        "            for param in model_hf.encoder.final_layer_norm.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    if FREEZE_DECODER_LAYER_COUNT > -1:\n",
        "        # We freeze here the embeddings of the model\n",
        "        for param in model_hf.shared.parameters():\n",
        "            param.requires_grad = False\n",
        "        if FREEZE_DECODER_LAYER_COUNT != 0:\n",
        "            for layer in model_hf.decoder.block[:min(12, FREEZE_DECODER_LAYER_COUNT)]:\n",
        "                for param in layer.parameters():\n",
        "                    param.requires_grad = False\n",
        "        if FREEZE_DECODER_LAYER_COUNT == len(model_hf.decoder.block)+1:\n",
        "            for param in model_hf.decoder.final_layer_norm.parameters():\n",
        "                param.requires_grad = False\n",
        "            for param in model_hf.lm_head.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    pytorch_total_params = sum(p.numel() for p in model_hf.parameters() if p.requires_grad)\n",
        "    print('Number of trainable parameters in base model:', pytorch_total_params)\n",
        "\n",
        "    return model_hf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gPKlVbH-rHkl",
      "metadata": {
        "id": "gPKlVbH-rHkl"
      },
      "outputs": [],
      "source": [
        "# Load optimizer\n",
        "\n",
        "def load_optimizer(model):\n",
        "    opt_parameters = model.parameters()\n",
        "    return torch.optim.AdamW(opt_parameters, lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33ceb2ae-6206-4e83-92b7-46b7a22c93d0",
      "metadata": {
        "id": "33ceb2ae-6206-4e83-92b7-46b7a22c93d0"
      },
      "outputs": [],
      "source": [
        "# Tokenize the inputs\n",
        "\n",
        "def tokenize_inputs(X_text='', X_head='', y='', X_annotype='', show_examples=False):\n",
        "    task_prefix = CUSTOM_PREFIX\n",
        "    if ADD_TASK_PREFIX:\n",
        "        if   OUTPUT_FORMAT in OUTPUT_FORMATS['t']:\n",
        "            task_prefix += 'type: '\n",
        "        elif OUTPUT_FORMAT in OUTPUT_FORMATS['p']:\n",
        "            task_prefix += 'polarity: '\n",
        "        elif OUTPUT_FORMAT in OUTPUT_FORMATS['i']:\n",
        "            task_prefix += 'intensity: '\n",
        "\n",
        "    pipe = ' | '\n",
        "    if REMOVE_PIPES_FROM_INPUT:\n",
        "        pipe = ' '\n",
        "\n",
        "    if   INPUT_FORMAT in ['T:A|S']:\n",
        "        X_pretokenized = [task_prefix + annotype + ' : ' + head + pipe + text for annotype, head, text in zip(X_annotype, X_head, X_text)]\n",
        "    elif INPUT_FORMAT in ['T:S|A']:\n",
        "        X_pretokenized = [task_prefix + annotype + ' : ' + text + pipe + head for annotype, head, text in zip(X_annotype, X_head, X_text)]\n",
        "    elif INPUT_FORMAT in INPUT_FORMATS['T|A|S']:\n",
        "        inner_separator = None\n",
        "        if ':' in INPUT_FORMAT:\n",
        "            inner_separator = ':'\n",
        "        if '=' in INPUT_FORMAT:\n",
        "            inner_separator = '='\n",
        "        X_pretokenized = []\n",
        "        for annotype, head, text in zip(X_annotype, X_head, X_text):\n",
        "            X_pretokenized.append(task_prefix)\n",
        "            for input_part in INPUT_FORMAT.split('|'):\n",
        "                if X_pretokenized[-1] != task_prefix:\n",
        "                    X_pretokenized[-1] += pipe\n",
        "                if input_part[0] == 'T':\n",
        "                    if inner_separator:\n",
        "                        X_pretokenized[-1] += 'type ' + inner_separator + ' '\n",
        "                    X_pretokenized[-1] += annotype\n",
        "                if input_part[0] == 'A':\n",
        "                    if inner_separator:\n",
        "                        X_pretokenized[-1] += 'aspect ' + inner_separator + ' '\n",
        "                    X_pretokenized[-1] += head\n",
        "                if input_part[0] == 'S':\n",
        "                    if inner_separator:\n",
        "                        X_pretokenized[-1] += 'sentence ' + inner_separator + ' '\n",
        "                    X_pretokenized[-1] += text\n",
        "\n",
        "    elif INPUT_FORMAT in ['A|S']:\n",
        "        X_pretokenized = [task_prefix + head + pipe + text for head, text in zip(X_head, X_text)]\n",
        "    elif INPUT_FORMAT in ['A:A|S:S']:\n",
        "        X_pretokenized = [task_prefix + 'aspect : ' + head + pipe + 'sentence : ' + text for head, text in zip(X_head, X_text)]\n",
        "    elif INPUT_FORMAT in ['A=A|S=S']:\n",
        "        X_pretokenized = [task_prefix + 'aspect = ' + head + pipe + 'sentence = ' + text for head, text in zip(X_head, X_text)]\n",
        "    elif INPUT_FORMAT in ['S|A']:\n",
        "        X_pretokenized = [task_prefix + text + pipe + head for text, head in zip(X_text, X_head)]\n",
        "    elif INPUT_FORMAT in ['S:S|A:A']:\n",
        "        X_pretokenized = [task_prefix + 'sentence : ' + text + pipe + 'aspect : ' + head for text, head in zip(X_text, X_head)]\n",
        "    elif INPUT_FORMAT in ['S=S|A=A']:\n",
        "        X_pretokenized = [task_prefix + 'sentence = ' + text + pipe + 'aspect = ' + head for text, head in zip(X_text, X_head)]\n",
        "\n",
        "    elif INPUT_FORMAT in ['S']:\n",
        "        X_pretokenized = task_prefix + X_text\n",
        "    elif INPUT_FORMAT in ['A']:\n",
        "        X_pretokenized = task_prefix + X_head\n",
        "    else:\n",
        "        print(\"INPUT FORMAT NOT SUPPORTED IN tokenize_inputs\")\n",
        "\n",
        "    if show_examples:\n",
        "        print(\"\\nPretokenized examples:\")\n",
        "        for i in range(1, min(len(y)+1, 4)):\n",
        "            print(f'\"{X_pretokenized[-i]}\" \\t/ {y[-i]}')\n",
        "        print()\n",
        "\n",
        "    Xy_tokenized = tokenizer(X_pretokenized, text_target=y, truncation=True)\n",
        "\n",
        "    return Xy_tokenized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8Wx14kixomjf",
      "metadata": {
        "id": "8Wx14kixomjf"
      },
      "outputs": [],
      "source": [
        "def batch_detokenize(tokens):\n",
        "    tokens = np.where(tokens != -100, tokens, tokenizer.pad_token_id) # Replace -100 in the labels as we can't decode them\n",
        "    texts = tokenizer.batch_decode(tokens, skip_special_tokens=True)\n",
        "\n",
        "    for i in range(len(texts)):\n",
        "        text = texts[i].strip()\n",
        "        if CAPITALIZATION_NORMALIZATION:\n",
        "            text = text.lower()\n",
        "        texts[i] = text\n",
        "\n",
        "    return texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZWryAdwqkzut",
      "metadata": {
        "id": "ZWryAdwqkzut"
      },
      "outputs": [],
      "source": [
        "print(tokenize_inputs([\"\"], [\"\"], [\"\"], [\"\"], show_examples=True))\n",
        "print()\n",
        "print(tokenize_inputs([\"Holding out for a hero\"], [\"hero\"], ['agreement arguing expressive intention sentiment'], ['sentiment'], show_examples=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1fb9aae-3aa3-47a4-befe-cf9a80978ebd",
      "metadata": {
        "id": "d1fb9aae-3aa3-47a4-befe-cf9a80978ebd"
      },
      "outputs": [],
      "source": [
        "# Create torch dataset\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels=None):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels:\n",
        "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])\n",
        "\n",
        "def get_dataset(Xy_tokenized):\n",
        "    dataset = Dataset(Xy_tokenized)\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b844adf-e40c-4712-b714-79ece6327c28",
      "metadata": {
        "id": "1b844adf-e40c-4712-b714-79ece6327c28"
      },
      "outputs": [],
      "source": [
        "# DataCollator\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nZulkQLFUh7r",
      "metadata": {
        "id": "nZulkQLFUh7r"
      },
      "outputs": [],
      "source": [
        "# DataLoader\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def get_dataloader(dataset, batch_size):\n",
        "    dataloader = DataLoader(\n",
        "        dataset, batch_size=batch_size, collate_fn=data_collator\n",
        "    )\n",
        "    return dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qc3Ifox5E4_j",
      "metadata": {
        "id": "qc3Ifox5E4_j"
      },
      "source": [
        "# Metrics and Training Arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_v4OXGINaQyV",
      "metadata": {
        "id": "_v4OXGINaQyV"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XN_RQA6laWIG",
      "metadata": {
        "id": "XN_RQA6laWIG"
      },
      "outputs": [],
      "source": [
        "def calculate_type_metrics(preds, targets, decimals=6):\n",
        "    targets = targets[:, :NUM_TYPE_CLASSES]\n",
        "    preds   = preds[:, :NUM_TYPE_CLASSES]\n",
        "\n",
        "    accuracy_list = np.sum(preds == targets, axis=0).astype(float) / preds.shape[0]\n",
        "    f1_list = f1_score(y_true=targets, y_pred=preds, zero_division=0, average=None)\n",
        "    precision_list = precision_score(y_true=targets, y_pred=preds, zero_division=0, average=None)\n",
        "    recall_list = recall_score(y_true=targets, y_pred=preds, zero_division=0, average=None)\n",
        "\n",
        "    TP = np.sum(preds & targets)\n",
        "    FP = np.sum(preds & (1-targets))\n",
        "    FN = np.sum((1-preds) & targets)\n",
        "\n",
        "    try:\n",
        "        micro_precision = TP / (TP + FP)\n",
        "    except:\n",
        "        micro_precision = 1\n",
        "\n",
        "    try:\n",
        "        micro_recall = TP / (TP + FN)\n",
        "    except:\n",
        "        micro_recall = 1\n",
        "\n",
        "    micro_f1 = statistics.harmonic_mean([micro_precision, micro_recall])\n",
        "    micro_accuracy = np.mean(preds == targets)\n",
        "\n",
        "    exact_match_ratio = np.mean(np.sum(preds == targets, axis = 1) == NUM_TYPE_CLASSES) # The percentage of samples that have all their labels classified correctly\n",
        "\n",
        "    return {\n",
        "        'type_exact_match_ratio': np.round(exact_match_ratio, decimals),\n",
        "        'type_micro_f1': np.round(micro_f1, decimals),\n",
        "        'type_micro_precision': np.round(micro_precision, decimals),\n",
        "        'type_micro_recall': np.round(micro_recall, decimals),\n",
        "        'type_micro_accuracy': np.round(np.mean(micro_accuracy), decimals),\n",
        "        'type_f1': np.round(f1_list, decimals).tolist(),\n",
        "        'type_precision': np.round(precision_list, decimals).tolist(),\n",
        "        'type_recall': np.round(recall_list, decimals).tolist(),\n",
        "        'type_accuracy': np.round(accuracy_list, decimals).tolist(),\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ebfftf57VPh0",
      "metadata": {
        "id": "Ebfftf57VPh0"
      },
      "outputs": [],
      "source": [
        "def calculate_polarity_f1_measure(extracted_polarity_preds, extracted_polarity_targets):\n",
        "    extracted_polarity_targets = np.argmax(extracted_polarity_targets, axis=-1)\n",
        "    extracted_polarity_preds   = np.argmax(extracted_polarity_preds,   axis=-1)\n",
        "    polarity_weighted_f1 = f1_score(extracted_polarity_targets, extracted_polarity_preds, average='weighted')\n",
        "    return polarity_weighted_f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7F1SuOxLaYRY",
      "metadata": {
        "id": "7F1SuOxLaYRY"
      },
      "outputs": [],
      "source": [
        "def calculate_polarity_correctness_score(extracted_polarity_preds, extracted_polarity_targets):\n",
        "    extracted_polarity_targets = np.argmax(extracted_polarity_targets, axis=-1)\n",
        "    extracted_polarity_preds   = np.argmax(extracted_polarity_preds,   axis=-1)\n",
        "    polarity_score = np.sum(extracted_polarity_preds == extracted_polarity_targets)\n",
        "    return polarity_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aTrmgODvD5Y_",
      "metadata": {
        "id": "aTrmgODvD5Y_"
      },
      "outputs": [],
      "source": [
        "def calculate_pipeline_polarity_correctness_score(extracted_polarity_preds, extracted_polarity_targets, correctly_predicted_types):\n",
        "    extracted_polarity_targets = np.argmax(extracted_polarity_targets, axis=-1)\n",
        "    extracted_polarity_preds   = np.argmax(extracted_polarity_preds,   axis=-1)\n",
        "    polarity_score = np.sum((extracted_polarity_preds == extracted_polarity_targets) * correctly_predicted_types)\n",
        "    return polarity_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dzNgqFOraaXS",
      "metadata": {
        "id": "dzNgqFOraaXS"
      },
      "outputs": [],
      "source": [
        "def calculate_polarity_metrics(preds, targets, decimals=6):\n",
        "    batch_size = len(preds)\n",
        "\n",
        "    if INPUT_FORMAT in INPUT_FORMATS['A|S']:\n",
        "        type_targets = targets[:, :NUM_TYPE_CLASSES]\n",
        "        type_preds   = preds[:, :NUM_TYPE_CLASSES]\n",
        "        polarity_targets = [ # [NUM_TYPE_CLASSES, batch_size, NUM_POLARITY_CLASSES]\n",
        "            targets[:,\n",
        "                NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+0:\n",
        "                NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+3\n",
        "            ] for i in range(NUM_TYPE_CLASSES)\n",
        "        ]\n",
        "        polarity_preds = [ # [NUM_TYPE_CLASSES, batch_size, NUM_POLARITY_CLASSES]\n",
        "            preds[:,\n",
        "                NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+0:\n",
        "                NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+3\n",
        "            ] for i in range(NUM_TYPE_CLASSES)\n",
        "        ]\n",
        "\n",
        "        extracted_polarity_targets = []\n",
        "        extracted_polarity_preds   = []\n",
        "        correctly_predicted_types   = []\n",
        "        for batch_i in range(batch_size):\n",
        "            for type_i in range(NUM_TYPE_CLASSES):\n",
        "                if type_targets[batch_i, type_i] == 1:\n",
        "                    extracted_polarity_targets.append(polarity_targets[type_i][batch_i])\n",
        "                    extracted_polarity_preds.append(polarity_preds[type_i][batch_i])\n",
        "                    correctly_predicted_types.append(1 if type_preds[batch_i, type_i] else 0)\n",
        "        extracted_polarity_targets = np.array(extracted_polarity_targets) # [np.sum(type_targets), NUM_polarity_CLASSES]\n",
        "        extracted_polarity_preds   = np.array(extracted_polarity_preds)   # [np.sum(type_targets), NUM_polarity_CLASSES]\n",
        "        correctly_predicted_types  = np.array(correctly_predicted_types)  # [np.sum(type_targets)]\n",
        "\n",
        "        number_of_samples = np.sum(type_targets)\n",
        "        polarity_pipeline_acc = calculate_pipeline_polarity_correctness_score(extracted_polarity_preds, extracted_polarity_targets, correctly_predicted_types) / number_of_samples\n",
        "\n",
        "    elif INPUT_FORMAT in INPUT_FORMATS['T|A|S']:\n",
        "        extracted_polarity_targets = targets\n",
        "        extracted_polarity_preds   = preds\n",
        "\n",
        "        number_of_samples = batch_size\n",
        "        polarity_pipeline_acc = 0\n",
        "\n",
        "    polarity_acc = calculate_polarity_correctness_score(extracted_polarity_preds, extracted_polarity_targets) / number_of_samples\n",
        "    polarity_weighted_f1 = calculate_polarity_f1_measure(extracted_polarity_preds, extracted_polarity_targets)\n",
        "\n",
        "    return {\n",
        "        'polarity_accuracy': np.round(polarity_acc, decimals),\n",
        "        'polarity_weighted_f1': np.round(polarity_weighted_f1, decimals),\n",
        "        'polarity_pipeline_accuracy': np.round(polarity_pipeline_acc, decimals),\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PY58rZzsKuvN",
      "metadata": {
        "id": "PY58rZzsKuvN"
      },
      "outputs": [],
      "source": [
        "# Convert 3-dim intensity vector to its corresponding number\n",
        "\n",
        "def get_intensity_id(vec):\n",
        "    vec = vec.tolist()\n",
        "    if vec == [1, 0, 0]:\n",
        "        return 0\n",
        "    if vec == [1, 1, 0]:\n",
        "        return 1\n",
        "    if vec == [0, 1, 0]:\n",
        "        return 2\n",
        "    if vec == [0, 1, 1]:\n",
        "        return 3\n",
        "    if vec == [0, 0, 1]:\n",
        "        return 4\n",
        "    return 1 # everything is equal to low-medium by default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KfWRGMa3IRto",
      "metadata": {
        "id": "KfWRGMa3IRto"
      },
      "outputs": [],
      "source": [
        "def calculate_intensity_d_correctness_score(extracted_intensity_preds, extracted_intensity_targets, d=1):\n",
        "    batch_size = len(extracted_intensity_preds)\n",
        "    intensity_score = 0\n",
        "    for i in range(batch_size):\n",
        "        target_id = get_intensity_id(extracted_intensity_targets[i]) # everything is equal to low-medium by default\n",
        "        pred_id   = get_intensity_id(extracted_intensity_preds[i])   # everything is equal to low-medium by default\n",
        "        if abs(target_id - pred_id) <= d:\n",
        "            intensity_score += 1\n",
        "    return intensity_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TmjDLJJjU-nJ",
      "metadata": {
        "id": "TmjDLJJjU-nJ"
      },
      "outputs": [],
      "source": [
        "def calculate_intensity_f1_measure(extracted_intensity_preds, extracted_intensity_targets):\n",
        "\n",
        "    whole = 1.0\n",
        "    with_penalty = 0\n",
        "    half_false = 1\n",
        "    thresh = 0.5\n",
        "    trues = {'medium': 0, 'medium-high': 0, 'low': 0, 'high': 0, 'low-medium': 0}  # TP\n",
        "    cnt = {'medium': 0, 'medium-high': 0, 'low': 0, 'high': 0, 'low-medium': 0}    # TP + FN\n",
        "    falses = {'medium': 0, 'medium-high': 0, 'low': 0, 'high': 0, 'low-medium': 0} # FP\n",
        "\n",
        "    preds_indices = np.argmax(extracted_intensity_preds, axis=-1)\n",
        "\n",
        "    for i in range(len(preds_indices)):\n",
        "\n",
        "        if preds_indices[i] == 0:\n",
        "            if extracted_intensity_targets[i][0] == 0 and  extracted_intensity_targets[i][1] == 0 and  extracted_intensity_targets[i][2] == 1:\n",
        "                falses['low'] += 1\n",
        "            if extracted_intensity_targets[i][0] == 0 and  extracted_intensity_targets[i][1] == 1 and  extracted_intensity_targets[i][2] == 0:\n",
        "                falses['low'] += half_false\n",
        "            if extracted_intensity_targets[i][0] == 0 and  extracted_intensity_targets[i][1] == 1 and  extracted_intensity_targets[i][2] == 1:\n",
        "                falses['low'] += half_false\n",
        "\n",
        "        if preds_indices[i] == 1:\n",
        "            if extracted_intensity_targets[i][0] == 0 and  extracted_intensity_targets[i][1] == 0 and  extracted_intensity_targets[i][2] == 1:\n",
        "                falses['medium'] += half_false\n",
        "            if extracted_intensity_targets[i][0] == 1 and  extracted_intensity_targets[i][1] == 0 and  extracted_intensity_targets[i][2] == 0:\n",
        "                falses['medium'] += half_false\n",
        "\n",
        "        if preds_indices[i] == 2:\n",
        "            if extracted_intensity_targets[i][0] == 1 and  extracted_intensity_targets[i][1] == 0 and  extracted_intensity_targets[i][2] == 0:\n",
        "                falses['high'] += 1\n",
        "            if extracted_intensity_targets[i][0] == 1 and  extracted_intensity_targets[i][1] == 1 and  extracted_intensity_targets[i][2] == 0:\n",
        "                falses['high'] += 1\n",
        "            if extracted_intensity_targets[i][0] == 0 and  extracted_intensity_targets[i][1] == 1 and  extracted_intensity_targets[i][2] == 1:\n",
        "                falses['high'] += half_false\n",
        "            if extracted_intensity_targets[i][0] == 0 and  extracted_intensity_targets[i][1] == 1 and  extracted_intensity_targets[i][2] == 0:\n",
        "                falses['high'] += half_false\n",
        "\n",
        "        if extracted_intensity_targets[i][0] == 1 and  extracted_intensity_targets[i][1] == 0 and  extracted_intensity_targets[i][2] == 0:\n",
        "            cnt['low'] += 1\n",
        "            if preds_indices[i] == 0:\n",
        "                trues['low'] += whole\n",
        "\n",
        "        elif extracted_intensity_targets[i][0] == 0 and  extracted_intensity_targets[i][1] == 1 and  extracted_intensity_targets[i][2] == 0:\n",
        "            cnt['medium'] += 1\n",
        "            if preds_indices[i] == 1:\n",
        "                trues['medium'] += whole\n",
        "            else:\n",
        "                trues['medium'] += with_penalty\n",
        "\n",
        "        elif extracted_intensity_targets[i][0] == 0 and  extracted_intensity_targets[i][1] == 0 and  extracted_intensity_targets[i][2] == 1:\n",
        "            cnt['high'] += 1\n",
        "            if preds_indices[i] == 2:\n",
        "                trues['high'] += whole\n",
        "\n",
        "        elif extracted_intensity_targets[i][0] == 1 and  extracted_intensity_targets[i][1] == 1 and  extracted_intensity_targets[i][2] == 0:\n",
        "            cnt['low-medium'] += 1\n",
        "            if preds_indices[i] == 0 or preds_indices[i] == 1:\n",
        "                trues['low-medium'] += whole\n",
        "\n",
        "        elif extracted_intensity_targets[i][0] == 0 and  extracted_intensity_targets[i][1] == 1 and  extracted_intensity_targets[i][2] == 1:\n",
        "            cnt['medium-high'] += 1\n",
        "            if preds_indices[i] == 1 or preds_indices[i] == 2:\n",
        "                trues['medium-high'] += whole\n",
        "\n",
        "    weighted_f1 = 0\n",
        "    weights = 0\n",
        "    for intensity_class in trues.keys():\n",
        "        try:\n",
        "            intensity_class_precision = trues[intensity_class] / (trues[intensity_class] + falses[intensity_class])\n",
        "        except:\n",
        "            intensity_class_precision = 1\n",
        "        try:\n",
        "            intensity_class_recall = trues[intensity_class] / cnt[intensity_class]\n",
        "        except:\n",
        "            intensity_class_recall = 1\n",
        "        intensity_class_f1 = statistics.harmonic_mean([intensity_class_precision, intensity_class_recall])\n",
        "        weighted_f1 += intensity_class_f1 * cnt[intensity_class]\n",
        "        weights += cnt[intensity_class]\n",
        "    intensity_weighted_f1 = weighted_f1 / weights\n",
        "\n",
        "    return intensity_weighted_f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bl-rW6LfacIX",
      "metadata": {
        "id": "bl-rW6LfacIX"
      },
      "outputs": [],
      "source": [
        "def calculate_intensity_correctness_score(extracted_intensity_preds, extracted_intensity_targets):\n",
        "    extracted_intensity_preds_argmax = np.argmax(extracted_intensity_preds, axis=-1)\n",
        "    intensity_score = 0\n",
        "    for i in range(len(extracted_intensity_preds_argmax)):\n",
        "        if (extracted_intensity_targets[i, extracted_intensity_preds_argmax[i]] == 1):\n",
        "            intensity_score += 1\n",
        "    return intensity_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "heRILuHg9DjH",
      "metadata": {
        "id": "heRILuHg9DjH"
      },
      "outputs": [],
      "source": [
        "def calculate_pipeline_intensity_correctness_score(extracted_intensity_preds, extracted_intensity_targets, correctly_predicted_types):\n",
        "    extracted_intensity_preds_argmax = np.argmax(extracted_intensity_preds, axis=-1)\n",
        "    intensity_score = 0\n",
        "    for i in range(len(extracted_intensity_preds_argmax)):\n",
        "        if correctly_predicted_types[i] and (extracted_intensity_targets[i, extracted_intensity_preds_argmax[i]] == 1):\n",
        "            intensity_score += 1\n",
        "    return intensity_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pmzE32JJafGz",
      "metadata": {
        "id": "pmzE32JJafGz"
      },
      "outputs": [],
      "source": [
        "def calculate_intensity_metrics(preds, targets, decimals=6):\n",
        "    batch_size = len(preds)\n",
        "\n",
        "    if INPUT_FORMAT in INPUT_FORMATS['A|S']:\n",
        "        type_targets = targets[:, :NUM_TYPE_CLASSES]\n",
        "        type_preds   = preds[:, :NUM_TYPE_CLASSES]\n",
        "        intensity_targets = [ # [NUM_TYPE_CLASSES, batch_size, NUM_POLARITY_CLASSES]\n",
        "            targets[:,\n",
        "                NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+3:\n",
        "                NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+6\n",
        "            ] for i in range(NUM_TYPE_CLASSES)\n",
        "        ]\n",
        "        intensity_preds = [ # [NUM_TYPE_CLASSES, batch_size, NUM_POLARITY_CLASSES]\n",
        "            preds[:,\n",
        "                NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+3:\n",
        "                NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+6\n",
        "            ] for i in range(NUM_TYPE_CLASSES)\n",
        "        ]\n",
        "\n",
        "        extracted_intensity_targets = []\n",
        "        extracted_intensity_preds   = []\n",
        "        correctly_predicted_types   = []\n",
        "        for batch_i in range(batch_size):\n",
        "            for type_i in range(NUM_TYPE_CLASSES):\n",
        "                if type_targets[batch_i, type_i] == 1:\n",
        "                    extracted_intensity_targets.append(intensity_targets[type_i][batch_i])\n",
        "                    extracted_intensity_preds.append(intensity_preds[type_i][batch_i])\n",
        "                    correctly_predicted_types.append(1 if type_preds[batch_i, type_i] else 0)\n",
        "        extracted_intensity_targets = np.array(extracted_intensity_targets) # [np.sum(type_targets), NUM_INTENSITY_CLASSES]\n",
        "        extracted_intensity_preds   = np.array(extracted_intensity_preds)   # [np.sum(type_targets), NUM_INTENSITY_CLASSES]\n",
        "        correctly_predicted_types   = np.array(correctly_predicted_types)   # [np.sum(type_targets)]\n",
        "\n",
        "        number_of_samples = np.sum(type_targets)\n",
        "        intensity_pipeline_acc = calculate_pipeline_intensity_correctness_score(extracted_intensity_preds, extracted_intensity_targets, correctly_predicted_types) / number_of_samples\n",
        "\n",
        "    elif INPUT_FORMAT in INPUT_FORMATS['T|A|S']:\n",
        "        extracted_intensity_targets = targets\n",
        "        extracted_intensity_preds = preds\n",
        "\n",
        "        number_of_samples = batch_size\n",
        "        intensity_pipeline_acc = 0\n",
        "\n",
        "    intensity_d0_acc = calculate_intensity_d_correctness_score(extracted_intensity_preds, extracted_intensity_targets, d=0) / number_of_samples\n",
        "    intensity_d1_acc = calculate_intensity_d_correctness_score(extracted_intensity_preds, extracted_intensity_targets, d=1) / number_of_samples\n",
        "    intensity_d2_acc = calculate_intensity_d_correctness_score(extracted_intensity_preds, extracted_intensity_targets, d=2) / number_of_samples\n",
        "    intensity_d3_acc = calculate_intensity_d_correctness_score(extracted_intensity_preds, extracted_intensity_targets, d=3) / number_of_samples\n",
        "    intensity_d4_acc = calculate_intensity_d_correctness_score(extracted_intensity_preds, extracted_intensity_targets, d=4) / number_of_samples\n",
        "    intensity_acc    = calculate_intensity_correctness_score(extracted_intensity_preds, extracted_intensity_targets)        / number_of_samples\n",
        "    intensity_weighted_f1 = calculate_intensity_f1_measure(extracted_intensity_preds, extracted_intensity_targets)\n",
        "\n",
        "    return {\n",
        "        'intensity_exact_match_ratio': np.round(intensity_d0_acc, decimals),\n",
        "        'intensity_d1_accuracy': np.round(intensity_d1_acc, decimals),\n",
        "        'intensity_d2_accuracy': np.round(intensity_d2_acc, decimals),\n",
        "        'intensity_d3_accuracy': np.round(intensity_d3_acc, decimals),\n",
        "        'intensity_d4_accuracy': np.round(intensity_d4_acc, decimals),\n",
        "        'intensity_accuracy': np.round(intensity_acc, decimals),\n",
        "        'intensity_weighted_f1': np.round(intensity_weighted_f1, decimals),\n",
        "        'intensity_pipeline_accuracy': np.round(intensity_pipeline_acc, decimals),\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ou_r9sNHahNV",
      "metadata": {
        "id": "Ou_r9sNHahNV"
      },
      "outputs": [],
      "source": [
        "def calculate_general_metrics(preds, targets, decimals=6):\n",
        "    batch_size = len(preds)\n",
        "\n",
        "    type_targets = targets[:, :NUM_TYPE_CLASSES]\n",
        "    polarity_targets = [ # [NUM_TYPE_CLASSES, batch_size, NUM_POLARITY_CLASSES]\n",
        "        targets[:,\n",
        "            NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+0:\n",
        "            NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+3\n",
        "        ] for i in range(NUM_TYPE_CLASSES)\n",
        "    ]\n",
        "    intensity_targets = [ # [NUM_TYPE_CLASSES, batch_size, NUM_POLARITY_CLASSES]\n",
        "        targets[:,\n",
        "            NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+3:\n",
        "            NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+6\n",
        "        ] for i in range(NUM_TYPE_CLASSES)\n",
        "    ]\n",
        "\n",
        "    type_preds = preds[:, :NUM_TYPE_CLASSES]\n",
        "    polarity_preds = [ # [NUM_TYPE_CLASSES, batch_size, NUM_POLARITY_CLASSES]\n",
        "        preds[:,\n",
        "            NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+0:\n",
        "            NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+3\n",
        "        ] for i in range(NUM_TYPE_CLASSES)\n",
        "    ]\n",
        "    intensity_preds = [ # [NUM_TYPE_CLASSES, batch_size, NUM_POLARITY_CLASSES]\n",
        "        preds[:,\n",
        "            NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+3:\n",
        "            NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+6\n",
        "        ] for i in range(NUM_TYPE_CLASSES)\n",
        "    ]\n",
        "\n",
        "    custom_accuracy = 0\n",
        "    exact_match_ratio = 0\n",
        "    for batch_i in range(batch_size):\n",
        "        exact_match_ratio_flag = True\n",
        "        for type_i in range(NUM_TYPE_CLASSES):\n",
        "            if type_preds[batch_i, type_i] == 1 and type_targets[batch_i, type_i] == 1:\n",
        "                type_correctness_score  = 1\n",
        "                polarity_correctness_score  = calculate_polarity_correctness_score(polarity_preds[type_i][batch_i:batch_i+1], polarity_targets[type_i][batch_i:batch_i+1])\n",
        "                intensity_correctness_score = calculate_intensity_correctness_score(intensity_preds[type_i][batch_i:batch_i+1], intensity_targets[type_i][batch_i:batch_i+1])\n",
        "                if (polarity_correctness_score < 1 or intensity_correctness_score < 1):\n",
        "                    exact_match_ratio_flag = False\n",
        "                custom_accuracy += (type_correctness_score/3 + polarity_correctness_score/3 + intensity_correctness_score/3) / NUM_TYPE_CLASSES\n",
        "            elif type_preds[batch_i, type_i] == 0 and type_targets[batch_i, type_i] == 0:\n",
        "                type_correctness_score = 1\n",
        "                custom_accuracy += type_correctness_score / NUM_TYPE_CLASSES\n",
        "            else:\n",
        "                exact_match_ratio_flag = False\n",
        "\n",
        "        if exact_match_ratio_flag == True:\n",
        "            exact_match_ratio += 1\n",
        "\n",
        "    custom_accuracy = custom_accuracy / batch_size\n",
        "    exact_match_ratio = exact_match_ratio / batch_size\n",
        "\n",
        "    return {\n",
        "        'custom_accuracy': np.round(custom_accuracy, decimals), # No points for wrong annotation type predictions and 1/5 for each correct negative annotation type predicitions and 1/15 of a point for each correct positive annotation type, polarity or intensity prediction\n",
        "        'exact_match_ratio': np.round(exact_match_ratio, decimals), # All annotation types and their corresponding polarities and intensities of each sample gotta be correct\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hWRoXjnE7Hp6",
      "metadata": {
        "id": "hWRoXjnE7Hp6"
      },
      "outputs": [],
      "source": [
        "# \" Oh | my | god \" => [\"Oh\", \"my\", \"god\"]\n",
        "def split_and_clean(text, separator=' '):\n",
        "    return [part_of_text.strip() for part_of_text in text.strip().split(separator)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "trzOgwF0HgFa",
      "metadata": {
        "id": "trzOgwF0HgFa"
      },
      "outputs": [],
      "source": [
        "def apply_on_vec(vec, t_id=None, p_id=None, i_id=None, t_ids=None, p_ids=None, i_ids=None):\n",
        "    t_index = None\n",
        "\n",
        "    if t_id:\n",
        "        t_ids = [t_id]\n",
        "    if t_ids:\n",
        "        for t_id in t_ids:\n",
        "            if t_id in type_classid2classname:\n",
        "                t_index = type_classid2classindex[t_id]\n",
        "                vec[t_index] = 1\n",
        "\n",
        "    if p_id:\n",
        "        p_ids = [p_id]\n",
        "    if p_ids:\n",
        "        p_startpos = NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*t_index if t_index else 0\n",
        "        for p_id in p_ids:\n",
        "            if p_id in polarity_classid2classname:\n",
        "                p_index = polarity_classid2classindex[p_id]\n",
        "                vec[p_startpos + p_index] = 1\n",
        "\n",
        "    if i_id:\n",
        "        i_ids = [i_id]\n",
        "    if i_ids:\n",
        "        i_startpos = NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*t_index+3 if t_index else 0\n",
        "        for i_id in i_ids:\n",
        "            if i_id in intensity_classid2classname:\n",
        "                i_index = intensity_classid2classindex[i_id]\n",
        "                vec[i_startpos + i_index] = 1\n",
        "\n",
        "    return vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9QvUtA4sNfLH",
      "metadata": {
        "id": "9QvUtA4sNfLH"
      },
      "outputs": [],
      "source": [
        "def outputs_tokens_to_vec(outputs_tokens):\n",
        "    outputs_text = batch_detokenize(outputs_tokens)\n",
        "    outputs_vec = np.zeros((len(outputs_tokens), 35), dtype=int) # Empty 35-dimensional vector\n",
        "\n",
        "    if OUTPUT_FORMAT in ['t', 't(ordered)']:\n",
        "        outputs_vec = np.zeros((len(outputs_tokens), 5), dtype=int) # Empty 5-dimensional vector\n",
        "        for batch_i in range(len(outputs_text)):\n",
        "            t_ids = split_and_clean(outputs_text[batch_i], ' ')\n",
        "            outputs_vec[batch_i] = apply_on_vec(outputs_vec[batch_i], t_ids=t_ids)\n",
        "\n",
        "    elif OUTPUT_FORMAT in ['p']:\n",
        "        outputs_vec = np.zeros((len(outputs_tokens), 3), dtype=int) # Empty 3-dimensional vector\n",
        "        for batch_i in range(len(outputs_text)):\n",
        "            p_ids = split_and_clean(outputs_text[batch_i], ' ')\n",
        "            outputs_vec[batch_i] = apply_on_vec(outputs_vec[batch_i], p_id=p_ids[0])\n",
        "\n",
        "    elif OUTPUT_FORMAT in ['i']:\n",
        "        outputs_vec = np.zeros((len(outputs_tokens), 3), dtype=int) # Empty 3-dimensional vector\n",
        "        for batch_i in range(len(outputs_text)):\n",
        "            i_ids = split_and_clean(outputs_text[batch_i], ' ')\n",
        "            outputs_vec[batch_i] = apply_on_vec(outputs_vec[batch_i], i_ids=i_ids)\n",
        "\n",
        "    elif OUTPUT_FORMAT in OUTPUT_FORMATS['t|p|i:'] + OUTPUT_FORMATS['t,p,i:'] + OUTPUT_FORMATS['t|p|i='] + OUTPUT_FORMATS['t,p,i=']:\n",
        "        outputs_vec = np.zeros((len(outputs_tokens), 35), dtype=int) # Empty 35-dimensional vector\n",
        "        cognitive_states_separator = '||' if '|' in OUTPUT_FORMAT else '|'\n",
        "        attributes_separator       = '|'  if '|' in OUTPUT_FORMAT else ','\n",
        "        values_separator           = ':'  if ':' in OUTPUT_FORMAT else '='\n",
        "        for batch_i in range(len(outputs_text)):\n",
        "            cognitive_states = split_and_clean(outputs_text[batch_i], cognitive_states_separator)\n",
        "            for cognitive_state in cognitive_states:\n",
        "                attributes = split_and_clean(cognitive_state, attributes_separator)\n",
        "                t_id =  split_and_clean(attributes[0], values_separator)[-1] if len(attributes) > 0 else ''\n",
        "                p_id =  split_and_clean(attributes[1], values_separator)[-1] if len(attributes) > 1 else ''\n",
        "                i_ids = split_and_clean(attributes[2], values_separator)[-1] if len(attributes) > 2 else ''\n",
        "                i_ids = split_and_clean(i_ids, ' ')\n",
        "                outputs_vec[batch_i] = apply_on_vec(outputs_vec[batch_i], t_id=t_id, p_id=p_id, i_ids=i_ids)\n",
        "\n",
        "    return outputs_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Romelqk1ajX-",
      "metadata": {
        "id": "Romelqk1ajX-"
      },
      "outputs": [],
      "source": [
        "def calculate_metrics(pred):\n",
        "    targets = np.array(pred.label_ids, dtype=int)\n",
        "    targets = outputs_tokens_to_vec(targets)\n",
        "\n",
        "    preds   = pred.predictions\n",
        "    preds   = outputs_tokens_to_vec(preds)\n",
        "\n",
        "    metrics = {}\n",
        "    sum = 0.0\n",
        "    n_tasks = 0\n",
        "\n",
        "    if OUTPUT_FORMAT in OUTPUT_FORMATS['p'] + OUTPUT_FORMATS['t|p|i:'] + OUTPUT_FORMATS['t,p,i:'] + OUTPUT_FORMATS['t|p|i='] + OUTPUT_FORMATS['t,p,i=']:\n",
        "        metrics.update(calculate_polarity_metrics(preds, targets))\n",
        "        sum += metrics['polarity_accuracy']\n",
        "        n_tasks += 1\n",
        "\n",
        "    if OUTPUT_FORMAT in OUTPUT_FORMATS['i'] + OUTPUT_FORMATS['t|p|i:'] + OUTPUT_FORMATS['t,p,i:'] + OUTPUT_FORMATS['t|p|i='] + OUTPUT_FORMATS['t,p,i=']:\n",
        "        metrics.update(calculate_intensity_metrics(preds, targets))\n",
        "        sum += metrics['intensity_accuracy']\n",
        "        n_tasks += 1\n",
        "\n",
        "    if OUTPUT_FORMAT in OUTPUT_FORMATS['t'] + OUTPUT_FORMATS['t|p|i:'] + OUTPUT_FORMATS['t,p,i:'] + OUTPUT_FORMATS['t|p|i='] + OUTPUT_FORMATS['t,p,i=']:\n",
        "        metrics.update(calculate_type_metrics(preds, targets))\n",
        "        sum += metrics['type_micro_f1']\n",
        "        n_tasks += 1\n",
        "\n",
        "    if OUTPUT_FORMAT in OUTPUT_FORMATS['t|p|i:'] + OUTPUT_FORMATS['t,p,i:'] + OUTPUT_FORMATS['t|p|i='] + OUTPUT_FORMATS['t,p,i=']:\n",
        "        metrics.update(calculate_general_metrics(preds, targets))\n",
        "\n",
        "    metrics['average_of_metrics'] = np.round(sum/n_tasks, 6)\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dfde22e-6ec5-409d-9d5f-bafb21d8d0e9",
      "metadata": {
        "id": "2dfde22e-6ec5-409d-9d5f-bafb21d8d0e9"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QdusgCNayB0B",
      "metadata": {
        "id": "QdusgCNayB0B"
      },
      "outputs": [],
      "source": [
        "# Training Arguments\n",
        "\n",
        "def get_training_args(fold_counter):\n",
        "    training_args = Seq2SeqTrainingArguments(\n",
        "        output_dir = f'models/{EXPERIMENT_NAME}_{fold_counter}',\n",
        "        overwrite_output_dir = True,\n",
        "        per_device_train_batch_size = PER_DEVICE_TRAIN_BATCH_SIZE,\n",
        "        per_device_eval_batch_size = PER_DEVICE_VAL_BATCH_SIZE,\n",
        "        local_rank = LOCAL_RANK,\n",
        "        fp16 = FP16,\n",
        "        fp16_opt_level = FP16_OPT_LEVEL,\n",
        "        evaluation_strategy = EVAL_STRATEGY,\n",
        "        logging_steps = LOGGING_STEPS,\n",
        "        save_strategy = SAVE_STRATEGY,\n",
        "        save_steps = LOGGING_STEPS,\n",
        "        save_total_limit = 1,\n",
        "        num_train_epochs = NUM_TRAIN_EPOCHS,\n",
        "        load_best_model_at_end = LOAD_BEST_MODEL_AT_END,\n",
        "        metric_for_best_model = METRIC_FOR_BEST_MODEL,\n",
        "        dataloader_num_workers = NUM_WORKERS,\n",
        "        seed = SEED,\n",
        "        group_by_length = True,\n",
        "        predict_with_generate = PREDICT_WITH_GENERATE,\n",
        "        report_to = \"none\",\n",
        "        full_determinism = True\n",
        "    )\n",
        "    print(\"Number of GPUs:\", training_args.n_gpu)\n",
        "    print(\"Parallel Mode:\", training_args.parallel_mode)\n",
        "    print()\n",
        "    return training_args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7705257c-d00c-4257-9f91-f1bfd918776a",
      "metadata": {
        "id": "7705257c-d00c-4257-9f91-f1bfd918776a"
      },
      "outputs": [],
      "source": [
        "# Setup trainer\n",
        "\n",
        "def setup_trainer(model, train_dataset, val_dataset, optimizer, fold_counter):\n",
        "    with torch.no_grad():\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "    training_args = get_training_args(fold_counter)\n",
        "    trainer = Seq2SeqTrainer(\n",
        "        model = model,\n",
        "        args = training_args,\n",
        "        optimizers = (optimizer, None),\n",
        "        train_dataset = train_dataset,\n",
        "        eval_dataset = val_dataset,\n",
        "        data_collator = data_collator,\n",
        "        compute_metrics = calculate_metrics,\n",
        "        callbacks = CALLBACKS\n",
        "    )\n",
        "    return trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "n1F5NUhkJ2bf",
      "metadata": {
        "id": "n1F5NUhkJ2bf"
      },
      "outputs": [],
      "source": [
        "# Train\n",
        "\n",
        "folds_train_log          = []\n",
        "folds_val_log            = []\n",
        "folds_test_log           = []\n",
        "\n",
        "for fold_counter in range(0, min(len(FOLDS), MAX_FOLDS)):\n",
        "\n",
        "    print(f'\\n\\033[1mFold {fold_counter+1}:\\033[0m')\n",
        "\n",
        "    set_seed()\n",
        "\n",
        "    fold_keys = FOLDS[fold_counter]\n",
        "    train_ids = csds_splits[fold_keys[0]]\n",
        "    val_ids   = csds_splits[fold_keys[1]]\n",
        "    test_ids  = csds_splits[fold_keys[2]]\n",
        "\n",
        "    train_objects, val_objects, test_objects = filter_csds_objects_all(csds_objects, train_ids, val_ids, test_ids)\n",
        "\n",
        "    train_input_target_dict, n_train_samples = prepare_inputs_and_targets(train_objects)\n",
        "    val_input_target_dict,   n_val_samples   = prepare_inputs_and_targets(val_objects)\n",
        "    test_input_target_dict,  n_test_samples  = prepare_inputs_and_targets(test_objects)\n",
        "\n",
        "    X_train = np.array(list(train_input_target_dict.keys()))\n",
        "    X_val   = np.array(list(val_input_target_dict.keys()))\n",
        "    X_test  = np.array(list(test_input_target_dict.keys()))\n",
        "\n",
        "    y_train = list(train_input_target_dict.values())\n",
        "    y_val   = list(val_input_target_dict.values())\n",
        "    y_test  = list(test_input_target_dict.values())\n",
        "\n",
        "    X_train_type, X_train_head, X_train_text = None, None, None\n",
        "    X_val_type,   X_val_head,   X_val_text   = None, None, None\n",
        "    X_test_type,  X_test_head,  X_test_text  = None, None, None\n",
        "\n",
        "    if   INPUT_FORMAT in INPUT_FORMATS['T|A|S']:\n",
        "        X_train_type, X_train_head, X_train_text = X_train[:, 0].tolist(), X_train[:, 1].tolist(), X_train[:, 2].tolist()\n",
        "        X_val_type,   X_val_head,   X_val_text   = X_val  [:, 0].tolist(), X_val  [:, 1].tolist(), X_val  [:, 2].tolist()\n",
        "        X_test_type,  X_test_head,  X_test_text  = X_test [:, 0].tolist(), X_test [:, 1].tolist(), X_test [:, 2].tolist()\n",
        "        Xy_train_tokenized = tokenize_inputs(X_train_text, X_train_head, y_train, X_train_type, show_examples=True)\n",
        "        Xy_val_tokenized   = tokenize_inputs(X_val_text,   X_val_head,   y_val,   X_val_type  )\n",
        "        Xy_test_tokenized  = tokenize_inputs(X_test_text,  X_test_head,  y_test,  X_test_type )\n",
        "    elif INPUT_FORMAT in INPUT_FORMATS['A|S']:\n",
        "        X_train_head, X_train_text = X_train[:, 0].tolist(), X_train[:, 1].tolist()\n",
        "        X_val_head,   X_val_text   = X_val  [:, 0].tolist(), X_val  [:, 1].tolist()\n",
        "        X_test_head,  X_test_text  = X_test [:, 0].tolist(), X_test [:, 1].tolist()\n",
        "        Xy_train_tokenized = tokenize_inputs(X_train_text, X_train_head, y_train, show_examples=True)\n",
        "        Xy_val_tokenized   = tokenize_inputs(X_val_text,   X_val_head,   y_val  )\n",
        "        Xy_test_tokenized  = tokenize_inputs(X_test_text,  X_test_head,  y_test )\n",
        "\n",
        "    n_samples = n_train_samples + n_val_samples + n_test_samples\n",
        "    print(f'Train set size:      {n_train_samples} \\t({100*n_train_samples/n_samples}%)')\n",
        "    print(f'Validation set size: {n_val_samples} \\t({100*n_val_samples/n_samples}%)')\n",
        "    print(f'Test set size:       {n_test_samples} \\t({100*n_test_samples/n_samples}%)')\n",
        "    print()\n",
        "\n",
        "    train_dataset = get_dataset(Xy_train_tokenized)\n",
        "    val_dataset   = get_dataset(Xy_val_tokenized)\n",
        "    test_dataset  = get_dataset(Xy_test_tokenized)\n",
        "\n",
        "    model_hf = load_model_hf()\n",
        "    model = model_hf\n",
        "    model = model.to(device)\n",
        "\n",
        "    optimizer = load_optimizer(model)\n",
        "    trainer = setup_trainer(model, train_dataset, val_dataset, optimizer, fold_counter)\n",
        "    logging.disable(logging.INFO)\n",
        "    trainer.train()\n",
        "\n",
        "    train_results = trainer.evaluate(train_dataset)\n",
        "    val_results  = trainer.evaluate(val_dataset)\n",
        "    test_results = trainer.evaluate(test_dataset)\n",
        "    logging.disable(logging.NOTSET)\n",
        "\n",
        "    folds_train_log.append(train_results)\n",
        "    folds_val_log.append(val_results)\n",
        "    folds_test_log.append(test_results)\n",
        "    print(\"train_results =\",          train_results)\n",
        "    print(\"val_results =\",            val_results)\n",
        "    print(\"test_results =\",           test_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f8pf4c2tEDY",
      "metadata": {
        "id": "8f8pf4c2tEDY"
      },
      "outputs": [],
      "source": [
        "for fold_counter in range(len(folds_val_log)):\n",
        "    if os.path.exists(f'models/{EXPERIMENT_NAME}_{fold_counter}'):\n",
        "        best_epoch = int(os.listdir(f'models/{EXPERIMENT_NAME}_{fold_counter}')[0].split('-')[-1]) * PER_DEVICE_TRAIN_BATCH_SIZE / n_train_samples\n",
        "        folds_val_log[fold_counter]['best_epoch'] = best_epoch\n",
        "        folds_test_log[fold_counter]['best_epoch'] = best_epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6vXgpwu2J2bf",
      "metadata": {
        "id": "6vXgpwu2J2bf"
      },
      "outputs": [],
      "source": [
        "print(folds_train_log)\n",
        "print(folds_val_log)\n",
        "print(folds_test_log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "j5lk3DzPJ2bf",
      "metadata": {
        "id": "j5lk3DzPJ2bf"
      },
      "outputs": [],
      "source": [
        "def print_log(folds_log, portion):\n",
        "    if portion == 'Train':\n",
        "        color = '\\033[1;31m'\n",
        "    elif portion == 'Validation':\n",
        "        color = '\\033[1;32m'\n",
        "    elif portion == 'Test':\n",
        "        color = '\\033[1;36m'\n",
        "\n",
        "    ignored_metrics = ['eval_runtime', 'eval_samples_per_second', 'eval_steps_per_second', 'epoch', 'best_epoch']\n",
        "    highlighted_metrics = ['eval_type_micro_f1', 'eval_polarity_accuracy', 'eval_intensity_accuracy', 'eval_average_of_metrics']\n",
        "\n",
        "    print(f'{color}{portion}:\\033[0m')\n",
        "    print(f'\\033[1mBased on steps with best {METRIC_FOR_BEST_MODEL}\\033[0m')\n",
        "\n",
        "    for metric_name in folds_log[0].keys():\n",
        "        if metric_name in ignored_metrics:\n",
        "            continue\n",
        "        metric_values_in_each_fold = np.round([fold_log[metric_name] for fold_log in folds_log], 6)\n",
        "        average = np.round(np.mean(metric_values_in_each_fold, axis=0), 6)\n",
        "        print()\n",
        "        if str(type(average)) == \"<class 'numpy.ndarray'>\":\n",
        "            print(f'\\033[1maverage {metric_name} of each type class:\\033[0m {average}')\n",
        "        elif metric_name in highlighted_metrics:\n",
        "            print(f'\\033[1m{metric_name}:\\033[0m {metric_values_in_each_fold}')\n",
        "            print(f'\\033[1maverage:\\033[0m {color}{average}\\033[0m')\n",
        "        else:\n",
        "            print(f'\\033[1m{metric_name}:\\033[0m {metric_values_in_each_fold}')\n",
        "            print(f'\\033[1maverage:\\033[0m {average}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "unugBZ_1aVqe",
      "metadata": {
        "id": "unugBZ_1aVqe"
      },
      "outputs": [],
      "source": [
        "print_log(folds_train_log, 'Train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LLbvbz9pgajZ",
      "metadata": {
        "id": "LLbvbz9pgajZ"
      },
      "outputs": [],
      "source": [
        "print_log(folds_val_log, 'Validation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ElfTO1c3Enmi",
      "metadata": {
        "id": "ElfTO1c3Enmi"
      },
      "outputs": [],
      "source": [
        "print_log(folds_test_log, 'Test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sQWxkAhRcIVM",
      "metadata": {
        "id": "sQWxkAhRcIVM"
      },
      "outputs": [],
      "source": [
        "print('\\033[1m Early Stopping: \\033[0m', end = '')\n",
        "print(f'{np.round(EARLY_STOPPING*LOGGING_STEPS*PER_DEVICE_TRAIN_BATCH_SIZE/n_train_samples, 2)} \\n', end='')\n",
        "\n",
        "print('\\033[1m Epochs: \\033[0m', end = '')\n",
        "epochs_in_each_fold = [fold_log['epoch'] for fold_log in folds_val_log]\n",
        "average = np.round(np.mean(epochs_in_each_fold, axis=0), 2)\n",
        "print(f'{average} \\n', end='')\n",
        "\n",
        "print('\\033[1m Epoch in Which the Best Results Were Achieved: \\033[0m', end = '')\n",
        "best_epochs_in_each_fold = [fold_log['best_epoch'] for fold_log in folds_val_log]\n",
        "average = np.round(np.mean(best_epochs_in_each_fold, axis=0), 2)\n",
        "print(f'{average} \\n', end='')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oOzPfkUAJ2bi",
      "metadata": {
        "id": "oOzPfkUAJ2bi"
      },
      "source": [
        "# What's wrong?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MpiRL3zTJ2bg",
      "metadata": {
        "id": "MpiRL3zTJ2bg"
      },
      "outputs": [],
      "source": [
        "if SHOW_WRONG_PREDICTIONS == True:\n",
        "    logging.disable(logging.INFO)\n",
        "    pred = trainer.predict(val_dataset)\n",
        "    logging.disable(logging.NOTSET)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HgqUPl1BJ2bg",
      "metadata": {
        "id": "HgqUPl1BJ2bg"
      },
      "outputs": [],
      "source": [
        "if SHOW_WRONG_PREDICTIONS == True:\n",
        "    targets_tokens = np.array(pred.label_ids, dtype=int)\n",
        "    targets_texts = batch_detokenize(targets_tokens)\n",
        "    targets_vecs = outputs_tokens_to_vec(targets_tokens)\n",
        "    preds_tokens = pred.predictions\n",
        "    preds_texts = batch_detokenize(preds_tokens)\n",
        "    preds_vecs = outputs_tokens_to_vec(preds_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tGJRde13J2bi",
      "metadata": {
        "id": "tGJRde13J2bi"
      },
      "outputs": [],
      "source": [
        "print('CLASSES:', TYPE_CLASSES)\n",
        "\n",
        "def classids2classnames(array):\n",
        "    res = []\n",
        "    for i in range(len(array)):\n",
        "        if array[i]:\n",
        "            res += [TYPE_CLASSES[i]]\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QyqPeQnvJ2bi",
      "metadata": {
        "id": "QyqPeQnvJ2bi"
      },
      "outputs": [],
      "source": [
        "if SHOW_WRONG_PREDICTIONS == True:\n",
        "    %mkdir results\n",
        "\n",
        "    all_predictions_dict = {}\n",
        "\n",
        "    with open(f'results/{EXPERIMENT_NAME}_wrong_predictions.txt', 'w') as f:\n",
        "\n",
        "        original_stdout = sys.stdout # Save a reference to the original standard output\n",
        "        sys.stdout = f # Change the standard output to the file we created.\n",
        "\n",
        "        CNT = 0\n",
        "        CNT_WRONG = 0\n",
        "        for i in range(len(preds_texts)):\n",
        "            CNT += 1\n",
        "\n",
        "            if not (preds_vecs[i] == targets_vecs[i]).all():\n",
        "                CNT_WRONG += 1\n",
        "                print(f'\\n#{CNT} (WRONG: #{CNT_WRONG})'\n",
        "                    f'\\nHead: {repr(X_val_head[i])}',\n",
        "                    f'\\nText: {repr(X_val_text[i])}',\n",
        "                    f'\\nPred: <{preds_texts[i]}> \\t / {preds_vecs[i].tolist()}',\n",
        "                    f'\\nGold: <{targets_texts[i]}> \\t / {targets_vecs[i].tolist()}')\n",
        "            else:\n",
        "                print(f'\\n#{CNT}'\n",
        "                    f'\\nHead: {repr(X_val_head[i])}',\n",
        "                    f'\\nText: {repr(X_val_text[i])}',\n",
        "                    f'\\nPred: <{preds_texts[i]}> \\t / {preds_vecs[i].tolist()}',\n",
        "                    f'\\nGold: <{targets_texts[i]}> \\t / {targets_vecs[i].tolist()}')\n",
        "\n",
        "            all_predictions_dict[i] = {\n",
        "                'head': X_val_head[i],\n",
        "                'text': X_val_text[i],\n",
        "                'pred': preds_texts[i],\n",
        "                'gold': targets_texts[i],\n",
        "                'pred_vec': preds_vecs[i].tolist(),\n",
        "                'gold_vec': targets_vecs[i].tolist(),\n",
        "                'type': None if X_val_type is None else X_val_type[i]\n",
        "            }\n",
        "\n",
        "        sys.stdout = original_stdout # Reset the standard output to its original value\n",
        "\n",
        "    with open(f'results/{EXPERIMENT_NAME}_all_predictions.json', 'w') as f:\n",
        "        json.dump(all_predictions_dict, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0CEl0LWK9cxA",
      "metadata": {
        "id": "0CEl0LWK9cxA"
      },
      "outputs": [],
      "source": [
        "if SHOW_WRONG_PREDICTIONS == True:\n",
        "    count_targets = np.sum(np.sum(targets_vecs[:, :NUM_TYPE_CLASSES], axis=1) > 1)\n",
        "    count_preds = np.sum(np.sum(preds_vecs[:, :NUM_TYPE_CLASSES], axis=1) > 1)\n",
        "    print(f' Actual multi-type samples:    {count_targets}\\n Predicted multi-type samples: {count_preds}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GlNaPZ35bskZ",
      "metadata": {
        "id": "GlNaPZ35bskZ"
      },
      "source": [
        "# Confusion Matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "v488jO6sbsOC",
      "metadata": {
        "id": "v488jO6sbsOC"
      },
      "outputs": [],
      "source": [
        "# Type\n",
        "\n",
        "if OUTPUT_FORMAT in OUTPUT_FORMATS['t']:\n",
        "    fig, axes = plt.subplots(ncols=5, figsize=(14, 3))\n",
        "    cms = multilabel_confusion_matrix(targets_vecs, preds_vecs)\n",
        "    for i in range(NUM_TYPE_CLASSES):\n",
        "        sns.heatmap(cms[i], ax=axes[i], annot=True, square=True, cbar=False, fmt='d', cmap='Blues')\n",
        "        axes[i].set_title(TYPE_CLASSES[i])\n",
        "\n",
        "        sum_x = np.sum(cms[i], axis=0)\n",
        "        xticklabels = [f'{k} (x{sum_x[k]})' for k in range(len(sum_x))]\n",
        "        sum_y = np.sum(cms[i], axis=1)\n",
        "        yticklabels = [f'{k} (x{sum_y[k]})' for k in range(len(sum_y))]\n",
        "        axes[i].set_xticklabels(xticklabels, rotation=30)\n",
        "        axes[i].set_yticklabels(yticklabels, rotation=30)\n",
        "\n",
        "        P = np.around(cms[i][1,1]/(cms[i][1,1]+cms[i][0,1])*100, 1)\n",
        "        R = np.around(cms[i][1,1]/(cms[i][1,1]+cms[i][1,0])*100, 1)\n",
        "        F = np.around(statistics.harmonic_mean([P/100, R/100])*100, 1)\n",
        "        cnt = np.sum(cms[i][1])\n",
        "        axes[i].set_xlabel(f'Predicted label\\nR: {R} | P: {P} | F1: {F}\\nCount in Dev Set: {cnt}')\n",
        "        axes[i].set_ylabel('True label')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LQFtcz2LrRT_",
      "metadata": {
        "id": "LQFtcz2LrRT_"
      },
      "outputs": [],
      "source": [
        "# Polarity\n",
        "\n",
        "if OUTPUT_FORMAT in OUTPUT_FORMATS['p']:\n",
        "    fig, axes = plt.subplots(ncols=5, nrows=2, figsize=(14, 6.5))\n",
        "\n",
        "    # Complete\n",
        "    cm = confusion_matrix(np.argmax(targets_vecs, axis=1), np.argmax(preds_vecs, axis=1))\n",
        "    sns.heatmap(cm, ax=axes[0,0], annot=True, square=True, cbar=False, fmt='d', cmap='Greens')\n",
        "    axes[0,0].set_title('All Types')\n",
        "\n",
        "    sum_x = np.sum(cm, axis=0)\n",
        "    xticklabels = [f'{k} (x{sum_x[k]})' for k in range(len(sum_x))]\n",
        "    sum_y = np.sum(cm, axis=1)\n",
        "    yticklabels = [f'{k} (x{sum_y[k]})' for k in range(len(sum_y))]\n",
        "    axes[0,0].set_xticklabels(xticklabels, rotation=30)\n",
        "    axes[0,0].set_yticklabels(yticklabels, rotation=30)\n",
        "\n",
        "    acc = np.around(calculate_polarity_correctness_score(preds_vecs, targets_vecs) / len(targets_vecs) * 100, 1)\n",
        "    f1  = np.around(calculate_polarity_f1_measure(preds_vecs, targets_vecs) * 100, 1)\n",
        "    axes[0,0].set_xlabel(f'Predicted label\\nAcc: {acc} | F1: {f1}\\nCount in Dev Set: {len(targets_vecs)}')\n",
        "    axes[0,0].set_ylabel('True label')\n",
        "\n",
        "    for j in range(1, len(TYPE_CLASSES)):\n",
        "        axes[0,j].set_visible(False)\n",
        "\n",
        "    for j in range(len(TYPE_CLASSES)):\n",
        "        t = TYPE_CLASSES[j]\n",
        "        t_targets_vecs = []\n",
        "        t_preds_vecs = []\n",
        "\n",
        "        for i in range(len(X_val_type)):\n",
        "            if X_val_type[i] == t:\n",
        "                t_targets_vecs.append(targets_vecs[i])\n",
        "                t_preds_vecs.append(preds_vecs[i])\n",
        "\n",
        "        cm = confusion_matrix(np.argmax(t_targets_vecs, axis=1), np.argmax(t_preds_vecs, axis=1))\n",
        "        sns.heatmap(cm, ax=axes[1,j], annot=True, cbar=False, square=True, fmt='d', cmap='Greens')\n",
        "        axes[1,j].set_title(t)\n",
        "\n",
        "        sum_x = np.sum(cm, axis=0)\n",
        "        xticklabels = [f'{k} (x{sum_x[k]})' for k in range(len(sum_x))]\n",
        "        sum_y = np.sum(cm, axis=1)\n",
        "        yticklabels = [f'{k} (x{sum_y[k]})' for k in range(len(sum_y))]\n",
        "        axes[1,j].set_xticklabels(xticklabels, rotation=30)\n",
        "        axes[1,j].set_yticklabels(yticklabels, rotation=30)\n",
        "\n",
        "        acc = np.around(calculate_polarity_correctness_score(t_preds_vecs, t_targets_vecs) / len(t_targets_vecs) * 100, 1)\n",
        "        f1  = np.around(calculate_polarity_f1_measure(t_preds_vecs, t_targets_vecs) * 100, 1)\n",
        "        axes[1,j].set_xlabel(f'Predicted label\\nAcc: {acc} | F1: {f1}\\nCount in Dev Set: {len(t_targets_vecs)}')\n",
        "        axes[1,j].set_ylabel('True label')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bM7VEy5MlfcG",
      "metadata": {
        "id": "bM7VEy5MlfcG"
      },
      "outputs": [],
      "source": [
        "if OUTPUT_FORMAT in OUTPUT_FORMATS['i']:\n",
        "\n",
        "    for i in range(len(preds_vecs)):\n",
        "        if (preds_vecs[i] == [1, 0, 1]).all():\n",
        "            print(i, preds_vecs[i])\n",
        "        if (preds_vecs[i] == [1, 0, 1]).all():\n",
        "            print(i, preds_vecs[i])\n",
        "        if (preds_vecs[i] == [0, 0, 0]).all():\n",
        "            print(i, preds_vecs[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9mVeHAgkjoi6",
      "metadata": {
        "id": "9mVeHAgkjoi6"
      },
      "outputs": [],
      "source": [
        "# Intensity\n",
        "\n",
        "if OUTPUT_FORMAT in OUTPUT_FORMATS['i']:\n",
        "    fig, axes = plt.subplots(ncols=5, nrows=2, figsize=(16, 8))\n",
        "\n",
        "    # Complete\n",
        "    targets_ids = [get_intensity_id(targets_vecs[i]) for i in range(len(preds_vecs))]\n",
        "    preds_ids   = [get_intensity_id(preds_vecs[i])   for i in range(len(preds_vecs))]\n",
        "    cm = confusion_matrix(targets_ids, preds_ids)\n",
        "    sns.heatmap(cm, ax=axes[0,0], annot=True, square=True, cbar=False, fmt='d', cmap='YlOrBr')\n",
        "    axes[0,0].set_title('All Types')\n",
        "\n",
        "    sum_x = np.sum(cm, axis=0)\n",
        "    xticklabels = [f'{k} (x{sum_x[k]})' for k in range(len(sum_x))]\n",
        "    sum_y = np.sum(cm, axis=1)\n",
        "    yticklabels = [f'{k} (x{sum_y[k]})' for k in range(len(sum_y))]\n",
        "    axes[0,0].set_xticklabels(xticklabels, rotation=30)\n",
        "    axes[0,0].set_yticklabels(yticklabels, rotation=30)\n",
        "\n",
        "    acc = np.around(calculate_intensity_correctness_score(np.array(preds_vecs), np.array(targets_vecs)) / len(targets_vecs) * 100, 1)\n",
        "    f1 = np.around(calculate_intensity_f1_measure(np.array(preds_vecs), np.array(targets_vecs)) * 100, 1)\n",
        "    d0 = np.around(calculate_intensity_d_correctness_score(np.array(preds_vecs), np.array(targets_vecs), d=0) / len(targets_vecs) * 100, 1)\n",
        "    d1 = np.around(calculate_intensity_d_correctness_score(np.array(preds_vecs), np.array(targets_vecs), d=1) / len(targets_vecs) * 100, 1)\n",
        "    d2 = np.around(calculate_intensity_d_correctness_score(np.array(preds_vecs), np.array(targets_vecs), d=2) / len(targets_vecs) * 100, 1)\n",
        "    d3 = np.around(calculate_intensity_d_correctness_score(np.array(preds_vecs), np.array(targets_vecs), d=3) / len(targets_vecs) * 100, 1)\n",
        "    d4 = np.around(calculate_intensity_d_correctness_score(np.array(preds_vecs), np.array(targets_vecs), d=4) / len(targets_vecs) * 100, 1)\n",
        "    axes[0,0].set_xlabel(f'Predicted label\\nAcc: {acc} | F1: {f1} | EMR: {d0}\\nD1: {d1} | D2: {d2} | D3: {d3} | D4: {d4}\\nCount in Dev Set: {len(targets_vecs)}')\n",
        "    axes[0,0].set_ylabel('True label')\n",
        "\n",
        "    for j in range(1, len(TYPE_CLASSES)):\n",
        "        axes[0,j].set_visible(False)\n",
        "\n",
        "    for j in range(len(TYPE_CLASSES)):\n",
        "        t = TYPE_CLASSES[j]\n",
        "        t_targets_vecs = []\n",
        "        t_preds_vecs = []\n",
        "\n",
        "        for i in range(len(X_val_type)):\n",
        "            if X_val_type[i] == t:\n",
        "                t_targets_vecs.append(targets_vecs[i])\n",
        "                t_preds_vecs.append(preds_vecs[i])\n",
        "\n",
        "        t_targets_ids = [get_intensity_id(t_targets_vecs[i]) for i in range(len(t_preds_vecs))]\n",
        "        t_preds_ids   = [get_intensity_id(t_preds_vecs[i])   for i in range(len(t_preds_vecs))]\n",
        "        cm = confusion_matrix(t_targets_ids, t_preds_ids)\n",
        "        sns.heatmap(cm, ax=axes[1,j], annot=True, cbar=False, square=True, fmt='d', cmap='YlOrBr')\n",
        "        axes[1,j].set_title(t)\n",
        "\n",
        "        sum_x = np.sum(cm, axis=0)\n",
        "        xticklabels = [f'{k} (x{sum_x[k]})' for k in range(len(sum_x))]\n",
        "        sum_y = np.sum(cm, axis=1)\n",
        "        yticklabels = [f'{k} (x{sum_y[k]})' for k in range(len(sum_y))]\n",
        "        axes[1,j].set_xticklabels(xticklabels, rotation=30)\n",
        "        axes[1,j].set_yticklabels(yticklabels, rotation=30)\n",
        "\n",
        "        acc = np.around(calculate_intensity_correctness_score(np.array(t_preds_vecs), np.array(t_targets_vecs)) / len(t_targets_vecs) * 100, 1)\n",
        "        f1 = np.around(calculate_intensity_f1_measure(np.array(t_preds_vecs), np.array(t_targets_vecs)) * 100, 1)\n",
        "        d0 = np.around(calculate_intensity_d_correctness_score(np.array(t_preds_vecs), np.array(t_targets_vecs), d=0) / len(t_targets_vecs) * 100, 1)\n",
        "        d1 = np.around(calculate_intensity_d_correctness_score(np.array(t_preds_vecs), np.array(t_targets_vecs), d=1) / len(t_targets_vecs) * 100, 1)\n",
        "        d2 = np.around(calculate_intensity_d_correctness_score(np.array(t_preds_vecs), np.array(t_targets_vecs), d=2) / len(t_targets_vecs) * 100, 1)\n",
        "        d3 = np.around(calculate_intensity_d_correctness_score(np.array(t_preds_vecs), np.array(t_targets_vecs), d=3) / len(t_targets_vecs) * 100, 1)\n",
        "        d4 = np.around(calculate_intensity_d_correctness_score(np.array(t_preds_vecs), np.array(t_targets_vecs), d=4) / len(t_targets_vecs) * 100, 1)\n",
        "        axes[1,j].set_xlabel(f'Predicted label\\nAcc: {acc} | F1: {f1} | EMR: {d0}\\nD1: {d1} | D2: {d2} | D3: {d3} | D4: {d4}\\nCount in Dev Set: {len(t_targets_vecs)}')\n",
        "        axes[1,j].set_ylabel('True label')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pK5AmBQa4sg8",
      "metadata": {
        "id": "pK5AmBQa4sg8"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B7_EGzBemWws",
      "metadata": {
        "id": "B7_EGzBemWws"
      },
      "outputs": [],
      "source": [
        "if STORE_RESULTS != []:\n",
        "\n",
        "    %mkdir results\n",
        "\n",
        "    if not os.path.exists('results/results.csv'):\n",
        "        with open(f'results/results.csv', 'w') as f:\n",
        "            original_stdout = sys.stdout # Save a reference to the original standard output\n",
        "            sys.stdout = f # Change the standard output to the file we created.\n",
        "\n",
        "            print('Experiment Name, ', end='')\n",
        "            for metric_name in STORE_RESULTS:\n",
        "                print(f'val {metric_name[5:].replace(\"_\", \" \").replace(\"type\", \"T\").replace(\"polarity\", \"P\").replace(\"intensity\", \"I\").replace(\"accuracy\", \"ACC\").replace(\"exact match ratio\", \"EMR\").replace(\"f1\", \"F1\").replace(\"micro \", \"\").replace(\"weighted\", \"\").replace(\"average of metrics\", \"AVG\")}, ', end='')\n",
        "            for metric_name in STORE_RESULTS:\n",
        "                print(f'tst {metric_name[5:].replace(\"_\", \" \").replace(\"type\", \"T\").replace(\"polarity\", \"P\").replace(\"intensity\", \"I\").replace(\"accuracy\", \"ACC\").replace(\"exact match ratio\", \"EMR\").replace(\"f1\", \"F1\").replace(\"micro \", \"\").replace(\"weighted\", \"\").replace(\"average of metrics\", \"AVG\")}, ', end='')\n",
        "            print(f'earlystopping, ', end='')\n",
        "            print(f'epochs, ', end='')\n",
        "            print(f'best epoch, ', end = '')\n",
        "            print()\n",
        "\n",
        "            sys.stdout = original_stdout # Reset the standard output to its original value\n",
        "\n",
        "    with open(f'results/results.csv', 'a') as f:\n",
        "        original_stdout = sys.stdout # Save a reference to the original standard output\n",
        "        sys.stdout = f # Change the standard output to the file we created.\n",
        "\n",
        "        print(f'{EXPERIMENT_NAME.replace(\".ipynb\", \"\").replace(\"_\", \" \").replace(\",\", \".\")}, ', end='')\n",
        "\n",
        "        for metric_name in STORE_RESULTS:\n",
        "            if metric_name in folds_val_log[0]:\n",
        "                metric_values_in_each_fold = [fold_log[metric_name] for fold_log in folds_val_log]\n",
        "                average = np.round(np.mean(metric_values_in_each_fold, axis=0), 6)\n",
        "                print(f'{average}, ', end='')\n",
        "            else:\n",
        "                print(f'-, ', end='')\n",
        "\n",
        "        for metric_name in STORE_RESULTS:\n",
        "            if metric_name in folds_val_log[0]:\n",
        "                metric_values_in_each_fold = [fold_log[metric_name] for fold_log in folds_test_log]\n",
        "                average = np.round(np.mean(metric_values_in_each_fold, axis=0), 6)\n",
        "                print(f'{average}, ', end='')\n",
        "            else:\n",
        "                print(f'-, ', end='')\n",
        "\n",
        "        print(f'{np.round(EARLY_STOPPING*LOGGING_STEPS*PER_DEVICE_TRAIN_BATCH_SIZE/n_train_samples, 2)}, ', end='')\n",
        "\n",
        "        epochs_in_each_fold = [fold_log['epoch'] for fold_log in folds_val_log]\n",
        "        average = np.round(np.mean(epochs_in_each_fold, axis=0), 2)\n",
        "        print(f'{average}, ', end='')\n",
        "\n",
        "        best_epochs_in_each_fold = [fold_log['best_epoch'] for fold_log in folds_val_log]\n",
        "        average = np.round(np.mean(best_epochs_in_each_fold, axis=0), 2)\n",
        "        print(f'{average}, ', end='')\n",
        "\n",
        "        print()\n",
        "\n",
        "        sys.stdout = original_stdout # Reset the standard output to its original value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7jnbajtw4oL8",
      "metadata": {
        "id": "7jnbajtw4oL8"
      },
      "outputs": [],
      "source": [
        "print_log(folds_test_log, 'Test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VUPs8IH-4j5V",
      "metadata": {
        "id": "VUPs8IH-4j5V"
      },
      "outputs": [],
      "source": [
        "print_log(folds_val_log, 'Validation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8xKJzxBizsw0",
      "metadata": {
        "id": "8xKJzxBizsw0"
      },
      "outputs": [],
      "source": [
        "%rm -r models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oaHBIW8bf2F7",
      "metadata": {
        "id": "oaHBIW8bf2F7"
      },
      "source": [
        "# Timer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zznzDHU3Z8qO",
      "metadata": {
        "id": "zznzDHU3Z8qO"
      },
      "outputs": [],
      "source": [
        "# Time data\n",
        "\n",
        "end_time = datetime.now() # end timer\n",
        "\n",
        "print('\\033[1mStart:\\033[0m {}'.format(start_time))\n",
        "print('\\033[1mEnd:\\033[0m {}'.format(end_time))\n",
        "print('\\n\\033[1mDuration:\\033[0m {}'.format(end_time - start_time))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
