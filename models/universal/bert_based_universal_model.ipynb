{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d_XrB849SNBz",
      "metadata": {
        "id": "d_XrB849SNBz"
      },
      "outputs": [],
      "source": [
        "# Doclists\n",
        "\n",
        "ULA_SUBSET_DOCS = ['ula/119CWL041', 'ula/RindnerBonnie', 'ula/HistoryGreek', 'ula/Article247_3500', 'ula/NapierDianne', 'ula/sw2071-UTF16-ms98-a-trans', 'ula/118CWL050', 'ula/114CUL059', 'ula/110CYL067', 'ula/PolkMaria', 'ula/116CUL034', 'ula/115CVL037', 'ula/118CWL049', 'ula/Article247_66', 'ula/110CYL068', 'ula/113CWL017', 'ula/112C-L015', 'ula/115CVL036', 'ula/115CVL035', 'ula/Article247_328', 'ula/114CUL060', 'ula/112C-L012', 'ula/118CWL048', 'ula/ReidSandra', 'ula/112C-L016', 'ula/HistoryJerusalem', 'ula/110CYL070', 'ula/sw2014-UTF16-ms98-a-trans', 'ula/112C-L014', 'ula/117CWL008', 'ula/sw2078-UTF16-ms98-a-trans', 'ula/110CYL071', 'ula/114CUL057', 'ula/116CUL032', 'ula/110CYL069', 'ula/117CWL009', 'ula/110CYL072', 'ula/chapter-10', 'ula/116CUL033', 'ula/ch5', 'ula/sw2015-ms98-a-trans', 'ula/113CWL018', 'ula/110CYL200', 'ula/Article247_327', 'ula/114CUL058', 'ula/112C-L013', 'ula/Article247_500', 'ula/Article247_400']\n",
        "ULA_LU_SUBSET_DOCS = ['ula/A1.E2-NEW', 'ula/wsj_1640.mrg-NEW', 'ula/AFGP-2002-600045-Trans', 'ula/20000410_nyt-NEW', 'ula/20000415_apw_eng-NEW', 'ula/AFGP-2002-602187-Trans', 'ula/20000815_AFP_ARB.0084.IBM-HA-NEW', 'ula/CNN_AARONBROWN_ENG_20051101_215800.partial-NEW', 'ula/20000424_nyt-NEW', 'ula/20000419_apw_eng-NEW', 'ula/20000416_xin_eng-NEW', 'ula/enron-thread-159550', 'ula/wsj_2465', 'ula/AFGP-2002-600002-Trans', 'ula/ENRON-pearson-email-25jul02', 'ula/im_401b_e73i32c22_031705-2', 'ula/A1.E1-NEW', 'ula/CNN_ENG_20030614_173123.4-NEW-1', 'ula/20000420_xin_eng-NEW', 'ula/IZ-060316-01-Trans-1', 'ula/sw2025-ms98-a-trans.ascii-1-NEW', 'ula/SNO-525', 'ula/AFGP-2002-600175-Trans', 'ula/602CZL285-1']\n",
        "XBANK_DOCS = ['xbank/wsj_0904', 'xbank/wsj_0760', 'xbank/wsj_0713', 'xbank/wsj_0709', 'xbank/wsj_0706', 'xbank/wsj_0662', 'xbank/wsj_0558', 'xbank/wsj_0555', 'xbank/wsj_0551', 'xbank/wsj_0542', 'xbank/wsj_0541', 'xbank/wsj_0332', 'xbank/wsj_0292', 'xbank/wsj_0189', 'xbank/wsj_0316', 'xbank/wsj_0175', 'xbank/wsj_0321', 'xbank/wsj_0176', 'xbank/wsj_0173', 'xbank/wsj_0026', 'xbank/wsj_0324', 'xbank/wsj_0187', 'xbank/wsj_0356', 'xbank/wsj_0325', 'xbank/wsj_0340', 'xbank/wsj_0679', 'xbank/wsj_0695', 'xbank/wsj_0661', 'xbank/wsj_0570', 'xbank/wsj_0557', 'xbank/wsj_0751', 'xbank/wsj_0805', 'xbank/wsj_0762', 'xbank/wsj_0736', 'xbank/wsj_0806', 'xbank/wsj_1040', 'xbank/wsj_1039', 'xbank/wsj_1042', 'xbank/wsj_0568', 'xbank/wsj_0778', 'xbank/wsj_0160', 'xbank/wsj_0136', 'xbank/wsj_0135', 'xbank/wsj_0127', 'xbank/wsj_0122', 'xbank/wsj_0032', 'xbank/wsj_0150', 'xbank/wsj_0165', 'xbank/wsj_0157', 'xbank/wsj_0151', 'xbank/wsj_0685', 'xbank/wsj_0168', 'xbank/wsj_0167', 'xbank/wsj_0161', 'xbank/wsj_0152', 'xbank/wsj_0073', 'xbank/wsj_0068', 'xbank/wsj_0171', 'xbank/wsj_0144', 'xbank/wsj_0991', 'xbank/wsj_0923', 'xbank/wsj_0907', 'xbank/wsj_0811', 'xbank/wsj_0667', 'xbank/wsj_0534', 'xbank/wsj_0924', 'xbank/wsj_0815', 'xbank/wsj_1038', 'xbank/wsj_1035', 'xbank/wsj_1033', 'xbank/wsj_0527', 'xbank/wsj_0928', 'xbank/wsj_0973', 'xbank/wsj_0950', 'xbank/wsj_0927', 'xbank/wsj_0376', 'xbank/wsj_0660', 'xbank/wsj_0650', 'xbank/wsj_0266', 'xbank/wsj_0006', 'xbank/wsj_0768', 'xbank/wsj_1073', 'xbank/wsj_0816', 'xbank/wsj_0610', 'xbank/wsj_0583']\n",
        "\n",
        "################################################################################\n",
        "\n",
        "#@title Parameters\n",
        "\n",
        "EXPERIMENT_NAME = 'bert'\n",
        "IGNORED_DOCS = ULA_SUBSET_DOCS + ULA_LU_SUBSET_DOCS + XBANK_DOCS # e.g. set it to ['non_fbis/06.11.16-17420'] to remove all objects with that specific document id\n",
        "MODEL_NAME = 'bert-base-uncased' #@param [\"bert-base-uncased\", \"bert-base-cased\"]\n",
        "INPUT_FORMAT = 'ES' #@param ['SE', 'ES']\n",
        "TEXT_KEY = 'clean_text' #@param [\"text\", \"clean_text\", \"w_text\"]\n",
        "HEAD_KEY = 'clean_head' #@param [\"head\", \"clean_head\", \"w_head\"]\n",
        "FREEZE_LAYER_COUNT = None\n",
        "LEARNING_RATE = 2.5e-5 #@param {\"type\": \"number\"}\n",
        "LR_DECAY_FACTOR = 1.00 #@param {\"type\": \"number\"}\n",
        "TYPE_THRESHOLD = 0.5\n",
        "INTENSITY_THRESHOLD = 0.5\n",
        "FP16 = False\n",
        "LOCAL_RANK = -1\n",
        "FP16_OPT_LEVEL = 'O1'\n",
        "TRAIN_BATCH_SIZE = 16 #@param {type: \"integer\"}\n",
        "VAL_BATCH_SIZE = 64 #@param {type: \"integer\"}\n",
        "TEST_BATCH_SIZE = 1\n",
        "LOGGING_STEPS = 400 #@param {type: \"integer\"}\n",
        "EVAL_STRATEGY = 'steps'\n",
        "SAVE_STRATEGY = 'steps'\n",
        "LOAD_BEST_MODEL_AT_END = True\n",
        "METRIC_FOR_BEST_MODEL = 'eval_average_of_metrics'\n",
        "DROPOUT = 0.1\n",
        "BCE_WEIGHT_EXPONENT = 0\n",
        "NUM_TRAIN_EPOCHS = 20\n",
        "EARLY_STOPPING = 3 # Set 0 to disable\n",
        "SEED = 0\n",
        "RANDOM_ASYNCHRONOUS_MTL = False\n",
        "SEQUENTIAL_ASYNCHRONOUS_MTL = [] # Empty list for off. [(1., 0., 0.), (0., 1., 0.)] for type only, then polarity only.\n",
        "TYPE_ONLY = False\n",
        "POLARITY_ONLY = False\n",
        "INTENSITY_ONLY = False\n",
        "ALPHA_TYPE  = 1.0\n",
        "ALPHA_POLARITY  = 1.0\n",
        "ALPHA_INTENSITY = 1.0\n",
        "DIVIDE_LOSS_BY = 'number of annotations' #@param ['batch size', 'number of annotations']\n",
        "MAX_FOLDS = 5 #@param {\"type\": \"integer\"}\n",
        "# Stop the iterartion after MAX_FOLDS folds.\n",
        "SHOW_WRONG_PREDICTIONS = True\n",
        "SHOW_ALL_PREDICTIONS = False\n",
        "STORE_RESULTS = [] # Array of metrics' names: save and store results of a suite of notebooks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4BT5kLjEk3Z",
      "metadata": {
        "id": "d4BT5kLjEk3Z"
      },
      "outputs": [],
      "source": [
        "# Dataset\n",
        "FETCH_DATASET_FROM_WEB = True # Set it to true, to download the dataset online\n",
        "SPLITS_URL = 'https://raw.githubusercontent.com/theSaeed/opinion-mining-using-llms/master/dataset/folds/tpi-folds.json'\n",
        "\n",
        "DATA_URL = '[replace dataset link here]' # WEB\n",
        "# OR\n",
        "FILE_ADDRESS = 'dataset/MPQA2.0_cleaned.json' # LOCAL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "z0Iu1Lp37Ymf",
      "metadata": {
        "id": "z0Iu1Lp37Ymf"
      },
      "outputs": [],
      "source": [
        "if TYPE_ONLY == True:\n",
        "    ALPHA_POLARITY = 0.0\n",
        "    ALPHA_INTENSITY = 0.0\n",
        "\n",
        "if POLARITY_ONLY == True:\n",
        "    ALPHA_TYPE = 0.0\n",
        "    ALPHA_INTENSITY = 0.0\n",
        "\n",
        "if INTENSITY_ONLY == True:\n",
        "    ALPHA_TYPE = 0.0\n",
        "    ALPHA_POLARITY = 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KQgSEbjZoaPX",
      "metadata": {
        "id": "KQgSEbjZoaPX"
      },
      "outputs": [],
      "source": [
        "!pwd\n",
        "%mkdir models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_SF7ZRNPzG1m",
      "metadata": {
        "id": "_SF7ZRNPzG1m"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce192a0a-9703-4393-ab55-c24cdd1222cc",
      "metadata": {
        "id": "ce192a0a-9703-4393-ab55-c24cdd1222cc"
      },
      "outputs": [],
      "source": [
        "# Libraries Required for Google Colab\n",
        "\n",
        "# %pip install transformers[sentencepiece]\n",
        "# %pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xyDbVHftZ0it",
      "metadata": {
        "id": "xyDbVHftZ0it"
      },
      "outputs": [],
      "source": [
        "# To assure deterministic results\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96f96831-ae2c-4adc-8730-cc07b9b5ba74",
      "metadata": {
        "id": "96f96831-ae2c-4adc-8730-cc07b9b5ba74"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import sys\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModel, TrainingArguments, Trainer, DataCollatorWithPadding, EarlyStoppingCallback, AutoConfig\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "import json\n",
        "from urllib.request import urlopen\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import statistics\n",
        "from datetime import datetime\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WHtALgYKZzhP",
      "metadata": {
        "id": "WHtALgYKZzhP"
      },
      "outputs": [],
      "source": [
        "# Start timer\n",
        "\n",
        "start_time = datetime.now()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d2ab8c6-603d-40af-875b-5b6f68f9accc",
      "metadata": {
        "id": "2d2ab8c6-603d-40af-875b-5b6f68f9accc"
      },
      "outputs": [],
      "source": [
        "# Setup device\n",
        "\n",
        "device_string = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device_hf = 0 if torch.cuda.is_available() else -1\n",
        "device = torch.device(device_string)\n",
        "print(\"Device:\", device)\n",
        "NUM_WORKERS = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ntWz_6EbfJG2",
      "metadata": {
        "id": "ntWz_6EbfJG2"
      },
      "outputs": [],
      "source": [
        "FOLDS = [\n",
        "    ['IDs_trainset_fold_1', 'IDs_validationset_fold_1', 'IDs_testset_fold_1'],\n",
        "    ['IDs_trainset_fold_2', 'IDs_validationset_fold_2', 'IDs_testset_fold_2'],\n",
        "    ['IDs_trainset_fold_3', 'IDs_validationset_fold_3', 'IDs_testset_fold_3'],\n",
        "    ['IDs_trainset_fold_4', 'IDs_validationset_fold_4', 'IDs_testset_fold_4'],\n",
        "    ['IDs_trainset_fold_5', 'IDs_validationset_fold_5', 'IDs_testset_fold_5'],\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rPg43SUKxudA",
      "metadata": {
        "id": "rPg43SUKxudA"
      },
      "outputs": [],
      "source": [
        "# Classes\n",
        "\n",
        "TYPE_CLASSES = ['agreement', 'arguing', 'expressive_subjectivity', 'intention', 'sentiment']\n",
        "POLARITY_CLASSES = ['negative', 'neutral', 'positive']\n",
        "INTENSITY_CLASSES = ['low', 'low-medium', 'medium', 'medium-high', 'high', 'high-extreme', 'extreme']\n",
        "POLARITY_DICT = {'negative': [1, 0, 0], 'neutral': [0, 1, 0], 'positive': [0, 0, 1]}\n",
        "INTENSITY_DICT = {'low': [1, 0, 0], 'low-medium': [1, 1, 0], 'medium': [0, 1, 0], 'medium-high': [0, 1, 1], 'high': [0, 0, 1], 'high-extreme': [0, 0, 1], 'extreme': [0, 0, 1]}\n",
        "NUM_TYPE_CLASSES = len(TYPE_CLASSES)\n",
        "NUM_POLARITY_CLASSES = len(POLARITY_CLASSES)\n",
        "NUM_INTENSITY_CLASSES = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "856a085e-a728-4a8e-8f75-193820216f52",
      "metadata": {
        "id": "856a085e-a728-4a8e-8f75-193820216f52"
      },
      "outputs": [],
      "source": [
        "# Callbacks\n",
        "\n",
        "CALLBACKS = []\n",
        "if EARLY_STOPPING > 0:\n",
        "    CALLBACKS.append(EarlyStoppingCallback(EARLY_STOPPING))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6a21171-f03f-45d1-9293-4bcb4183eb02",
      "metadata": {
        "id": "b6a21171-f03f-45d1-9293-4bcb4183eb02"
      },
      "outputs": [],
      "source": [
        "def set_seed():\n",
        "    random.seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65615ad0-5c82-4079-be75-122e75d8441c",
      "metadata": {
        "id": "65615ad0-5c82-4079-be75-122e75d8441c"
      },
      "source": [
        "# Preparing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28384faa-36ff-4caa-b598-4946d990c7ba",
      "metadata": {
        "id": "28384faa-36ff-4caa-b598-4946d990c7ba"
      },
      "outputs": [],
      "source": [
        "# Fetch the dataset\n",
        "\n",
        "if FETCH_DATASET_FROM_WEB:\n",
        "    response = urlopen(DATA_URL)\n",
        "    csds_collection = json.loads(response.read())\n",
        "    response = urlopen(SPLITS_URL)\n",
        "    csds_splits = json.loads(response.read())\n",
        "else:\n",
        "    with open(FILE_ADDRESS) as file:\n",
        "        csds_collection = json.load(file)\n",
        "    response = urlopen(SPLITS_URL)\n",
        "    csds_splits = json.loads(response.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "seHNkX9zWuDF",
      "metadata": {
        "id": "seHNkX9zWuDF"
      },
      "outputs": [],
      "source": [
        "# Create a map for class ids and class names\n",
        "\n",
        "type_classname2classid = {TYPE_CLASSES[i]:i for i in range(len(TYPE_CLASSES))}\n",
        "type_classid2classname = {i:TYPE_CLASSES[i] for i in range(len(TYPE_CLASSES))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Cao9699HZUIb",
      "metadata": {
        "id": "Cao9699HZUIb"
      },
      "outputs": [],
      "source": [
        "# Convert binary arrays to a decimal numbers and vice versa\n",
        "\n",
        "def bin2dec(bin_arrays):\n",
        "    result = []\n",
        "    for arr in bin_arrays:\n",
        "        result += [0]\n",
        "        for i in reversed(arr):\n",
        "            result[-1] *= 2\n",
        "            if i == 1:\n",
        "               result[-1] += 1\n",
        "    return result\n",
        "\n",
        "def dec2bin(arr):\n",
        "    result = []\n",
        "    for i in arr:\n",
        "        result += [[0] * NUM_TYPE_CLASSES]\n",
        "        for j in range(NUM_TYPE_CLASSES):\n",
        "            if i % 2 == 1:\n",
        "                result[-1][j] = 1\n",
        "            i //= 2\n",
        "    return result\n",
        "\n",
        "# Use first class in each sample for stratifying (Experimental)\n",
        "def bin_stratify_indicator(bin_arrays):\n",
        "    result = []\n",
        "    for arr in bin_arrays:\n",
        "        for i in range(len(arr)):\n",
        "            if arr[i] == 1:\n",
        "                result += [i]\n",
        "                break\n",
        "    return result\n",
        "\n",
        "def dec_stratify_indicator(dec_arr):\n",
        "    result = []\n",
        "    for i in dec_arr:\n",
        "        for j in range(NUM_TYPE_CLASSES):\n",
        "            if i % 2 == 1:\n",
        "                result += [j]\n",
        "                break\n",
        "            i //= 2\n",
        "    return result\n",
        "\n",
        "example = [[1, 0, 0, 0, 0], [0, 1, 1, 1, 1], [0, 0, 1, 1, 0]]\n",
        "print('Example:', example)\n",
        "print('bin2dec:', bin2dec(example))\n",
        "print('dec2bin(bin2dec):', dec2bin(bin2dec(example)))\n",
        "print('bin_stratify_indicator:', bin_stratify_indicator(example))\n",
        "print('dec_stratify_indicator:', dec_stratify_indicator(bin2dec(example)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WdjplMGJj_ld",
      "metadata": {
        "id": "WdjplMGJj_ld"
      },
      "outputs": [],
      "source": [
        "# Keep the objects with the specified ids\n",
        "\n",
        "def filter_csds_objects(csds_objects, subset_ids):\n",
        "    subset_ids_set = set(subset_ids)\n",
        "    return [\n",
        "        csds_object for csds_object in csds_objects if csds_object['unique_id'] in subset_ids_set\n",
        "    ]\n",
        "\n",
        "def filter_csds_objects_all(csds_objects, train_ids, val_ids, test_ids):\n",
        "    train_ids_set = set(train_ids)\n",
        "    val_ids_set = set(val_ids)\n",
        "    test_ids_set = set(test_ids)\n",
        "\n",
        "    train_objects, val_objects, test_objects = [], [], []\n",
        "\n",
        "    for csds_object in csds_objects:\n",
        "        if csds_object['unique_id'] in val_ids_set:\n",
        "            val_objects.append(csds_object)\n",
        "        elif csds_object['unique_id'] in test_ids_set:\n",
        "            test_objects.append(csds_object)\n",
        "        elif csds_object['unique_id'] in train_ids_set:\n",
        "            train_objects.append(csds_object)\n",
        "\n",
        "    return train_objects, val_objects, test_objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qgZfNCd9Qb4H",
      "metadata": {
        "id": "qgZfNCd9Qb4H"
      },
      "outputs": [],
      "source": [
        "# Preparing inputs and targets\n",
        "\n",
        "def prepare_inputs_and_targets(csds_objects):\n",
        "\n",
        "    input_output_dict = {}\n",
        "    n_samples = 0\n",
        "\n",
        "    for csds_object in csds_objects:\n",
        "        doc_id = csds_object['doc_id']\n",
        "        unique_id = csds_object['unique_id']\n",
        "        text = csds_object[TEXT_KEY]\n",
        "        head = csds_object[HEAD_KEY]\n",
        "        annotype  = csds_object['annotation_type']\n",
        "        polarity  = csds_object['polarity']\n",
        "        intensity = csds_object['intensity']\n",
        "\n",
        "        if annotype in TYPE_CLASSES and polarity in POLARITY_CLASSES and intensity in INTENSITY_CLASSES \\\n",
        "            and doc_id not in IGNORED_DOCS:\n",
        "\n",
        "            if (text, head) not in input_output_dict:\n",
        "                input_output_dict[(text, head)] = [0] * 35\n",
        "                n_samples += 1\n",
        "\n",
        "            type_id = type_classname2classid[annotype]\n",
        "            polarity_id_start  = NUM_TYPE_CLASSES + type_id * (NUM_POLARITY_CLASSES + NUM_INTENSITY_CLASSES)\n",
        "            polarity_id_end    = polarity_id_start + NUM_POLARITY_CLASSES\n",
        "            intensity_id_start = polarity_id_end\n",
        "            intensity_id_end   = intensity_id_start + NUM_INTENSITY_CLASSES\n",
        "\n",
        "            input_output_dict[(text, head)][type_id] = 1                                                     # target type\n",
        "            input_output_dict[(text, head)][polarity_id_start:polarity_id_end] = POLARITY_DICT[polarity]     # target polarity\n",
        "            input_output_dict[(text, head)][intensity_id_start:intensity_id_end] = INTENSITY_DICT[intensity] # target intensity\n",
        "\n",
        "    return input_output_dict, n_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee725191-73e1-47ee-a8d6-1465aa32b6f4",
      "metadata": {
        "id": "ee725191-73e1-47ee-a8d6-1465aa32b6f4"
      },
      "outputs": [],
      "source": [
        "# All samples\n",
        "\n",
        "csds_objects = csds_collection['csds_objects']\n",
        "\n",
        "train_val_test_objects = filter_csds_objects(csds_objects, csds_splits[FOLDS[0][0]]) + \\\n",
        "                         filter_csds_objects(csds_objects, csds_splits[FOLDS[0][1]]) + \\\n",
        "                         filter_csds_objects(csds_objects, csds_splits[FOLDS[0][2]])\n",
        "input_target_dict, n_samples = prepare_inputs_and_targets(train_val_test_objects)\n",
        "\n",
        "i = 2 # (i+1)-th sample\n",
        "print(f'inputs and targets for {i+1}-th csds object (out of {n_samples}):')\n",
        "print(f'input_output_dict.items()[{i}]:', list(input_target_dict.items())[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3545fa6-6969-45a9-b020-882f78a1322b",
      "metadata": {
        "id": "b3545fa6-6969-45a9-b020-882f78a1322b"
      },
      "outputs": [],
      "source": [
        "# Count the number of each target\n",
        "\n",
        "num_type  = {a_class:0 for a_class in TYPE_CLASSES}\n",
        "num_polarity  = {a_class:0 for a_class in POLARITY_CLASSES}\n",
        "num_intensity = {a_class:0 for a_class in INTENSITY_CLASSES}\n",
        "for targets in input_target_dict.values():\n",
        "    annotype = targets[:NUM_TYPE_CLASSES]\n",
        "    for i in range(len(annotype)):\n",
        "        num_type[type_classid2classname[i]] += 1 if annotype[i] == 1 else 0\n",
        "    for i in range(len(annotype), len(targets), NUM_POLARITY_CLASSES + NUM_INTENSITY_CLASSES):\n",
        "        for k, v in POLARITY_DICT.items():\n",
        "            if v == targets[i:i+3]:\n",
        "                num_polarity[k] += 1\n",
        "        for k, v in INTENSITY_DICT.items():\n",
        "            if v == targets[i+3:i+6]:\n",
        "                num_intensity[k] += 1\n",
        "print(num_type.items())\n",
        "print(num_polarity.items())\n",
        "print(num_intensity.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CaRqDRcglTSR",
      "metadata": {
        "id": "CaRqDRcglTSR"
      },
      "outputs": [],
      "source": [
        "# Prepare X and y\n",
        "\n",
        "X = list(input_target_dict.keys())\n",
        "y = list(input_target_dict.values())\n",
        "\n",
        "print(X[-3:])\n",
        "print(y[-3:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SlaL_2Zxkbzr",
      "metadata": {
        "id": "SlaL_2Zxkbzr"
      },
      "outputs": [],
      "source": [
        "X = np.array(X)\n",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pbxFmktBsQSw",
      "metadata": {
        "id": "pbxFmktBsQSw"
      },
      "outputs": [],
      "source": [
        "num_true_labels = np.sum(y[:, :NUM_TYPE_CLASSES], axis = 1)\n",
        "for j in range(len(TYPE_CLASSES)+1):\n",
        "    print(f'Labels with {j} ones:', len([i for i in num_true_labels if i == j]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MuHRyuSMAY20",
      "metadata": {
        "id": "MuHRyuSMAY20"
      },
      "outputs": [],
      "source": [
        "# Calculate pos weights for weighted BCELoss\n",
        "\n",
        "if BCE_WEIGHT_EXPONENT != 0:\n",
        "    pos_counts = np.sum(y, axis=0, dtype=float)\n",
        "    neg_counts = len(y) - pos_counts\n",
        "    pos_weights = neg_counts / (pos_counts + np.finfo(float).eps)\n",
        "    pos_weights = pos_weights ** BCE_WEIGHT_EXPONENT\n",
        "    pos_weights = torch.as_tensor(pos_weights, dtype=torch.float).to(device)\n",
        "else:\n",
        "    pos_weights = torch.as_tensor([1]*NUM_TYPE_CLASSES, dtype=torch.float).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37ab1607-bad3-4222-b15c-0ac3ec39acd5",
      "metadata": {
        "id": "37ab1607-bad3-4222-b15c-0ac3ec39acd5"
      },
      "source": [
        "# Preparing the model and torch dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b732e3ad-d4f0-4ee5-8d6c-0bdc523539f8",
      "metadata": {
        "id": "b732e3ad-d4f0-4ee5-8d6c-0bdc523539f8"
      },
      "outputs": [],
      "source": [
        "# Load the hf model and tokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "def load_model_hf():\n",
        "    model_hf = AutoModel.from_pretrained(\n",
        "        MODEL_NAME, resume_download=True,\n",
        "        config=AutoConfig.from_pretrained(MODEL_NAME)\n",
        "    )\n",
        "\n",
        "    if FREEZE_LAYER_COUNT is not None:\n",
        "        # We freeze the embeddings of the model here\n",
        "        for param in model_hf.embeddings.parameters():\n",
        "            param.requires_grad = False\n",
        "        if FREEZE_LAYER_COUNT != 0:\n",
        "            for layer in model_hf.encoder.layer[:FREEZE_LAYER_COUNT]:\n",
        "                for param in layer.parameters():\n",
        "                    param.requires_grad = False\n",
        "        if FREEZE_LAYER_COUNT == len(model_hf.encoder.layer):\n",
        "            for param in model_hf.pooler.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    pytorch_total_params = sum(p.numel() for p in model_hf.parameters() if p.requires_grad)\n",
        "    print('Number of trainable parameters in bert:', pytorch_total_params)\n",
        "\n",
        "    return model_hf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gPKlVbH-rHkl",
      "metadata": {
        "id": "gPKlVbH-rHkl"
      },
      "outputs": [],
      "source": [
        "# Load optimizer\n",
        "\n",
        "def load_optimizer(model):\n",
        "    opt_parameters = []\n",
        "    named_parameters = list(model.named_parameters())\n",
        "\n",
        "    layers_name = [\n",
        "        'pooler', 'layer.11', 'layer.10', 'layer.9', 'layer.8', 'layer.7',\n",
        "        'layer.6', 'layer.5', 'layer.4', 'layer.3', 'layer.2', 'layer.1',\n",
        "        'layer.0', 'embeddings'\n",
        "    ]\n",
        "    layers_lr = [LEARNING_RATE * (LR_DECAY_FACTOR ** i) for i in range(len(layers_name))]\n",
        "    print(\"Each layer's learning rate:\", layers_lr)\n",
        "\n",
        "    for (name, params) in named_parameters:\n",
        "        lr = LEARNING_RATE\n",
        "        for layer_name, layer_lr in zip(layers_name, layers_lr):\n",
        "            if layer_name in name:\n",
        "                lr = layer_lr\n",
        "                break\n",
        "        opt_parameters.append({\"params\": params, \"lr\": lr})\n",
        "\n",
        "    return torch.optim.AdamW(opt_parameters, lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33ceb2ae-6206-4e83-92b7-46b7a22c93d0",
      "metadata": {
        "id": "33ceb2ae-6206-4e83-92b7-46b7a22c93d0"
      },
      "outputs": [],
      "source": [
        "# Tokenize the inputs\n",
        "\n",
        "def tokenize_inputs(X_text, X_head):\n",
        "    if   INPUT_FORMAT == 'ES':\n",
        "        X_tokenized = tokenizer(X_head, X_text, truncation=True)\n",
        "    elif INPUT_FORMAT == 'SE':\n",
        "        X_tokenized = tokenizer(X_text, X_head, truncation=True)\n",
        "    return X_tokenized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZWryAdwqkzut",
      "metadata": {
        "id": "ZWryAdwqkzut"
      },
      "outputs": [],
      "source": [
        "print(tokenize_inputs([\"Holding out for a hero\"], [\"hero\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "r2ecT-tyHzZK",
      "metadata": {
        "id": "r2ecT-tyHzZK"
      },
      "outputs": [],
      "source": [
        "# Sort samples by their lengths to use less padding for more speed (It's not as effective after adding group_by_length=True to the arguments)\n",
        "\n",
        "def sort_samples(X_tokenized, y):\n",
        "    keys = [len(obj) for obj in X_tokenized['input_ids']]\n",
        "    sorted_idxs = np.argsort(keys)[::-1]\n",
        "    X_tokenized_sorted = {\n",
        "        'input_ids': [],\n",
        "        'token_type_ids': [],\n",
        "        'attention_mask': []\n",
        "    }\n",
        "    for i in sorted_idxs:\n",
        "        X_tokenized_sorted['input_ids'].append(X_tokenized['input_ids'][i])\n",
        "        X_tokenized_sorted['token_type_ids'].append(X_tokenized['token_type_ids'][i])\n",
        "        X_tokenized_sorted['attention_mask'].append(X_tokenized['attention_mask'][i])\n",
        "    y_sorted = np.array(y)[sorted_idxs].tolist()\n",
        "    return X_tokenized_sorted, y_sorted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1fb9aae-3aa3-47a4-befe-cf9a80978ebd",
      "metadata": {
        "id": "d1fb9aae-3aa3-47a4-befe-cf9a80978ebd"
      },
      "outputs": [],
      "source": [
        "# Create torch dataset\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels=None):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels:\n",
        "            item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])\n",
        "\n",
        "def get_dataset(X_tokenized, y):\n",
        "    X_tokenized_sorted, y_sorted = sort_samples(X_tokenized, y)\n",
        "    dataset = Dataset(X_tokenized_sorted, y_sorted)\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b844adf-e40c-4712-b714-79ece6327c28",
      "metadata": {
        "id": "1b844adf-e40c-4712-b714-79ece6327c28"
      },
      "outputs": [],
      "source": [
        "# DataCollator\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nZulkQLFUh7r",
      "metadata": {
        "id": "nZulkQLFUh7r"
      },
      "outputs": [],
      "source": [
        "# DataLoader\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def get_dataloader(dataset, batch_size):\n",
        "    dataloader = DataLoader(\n",
        "        dataset, batch_size=batch_size, collate_fn=data_collator\n",
        "    )\n",
        "    return dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nJC69pyUZhOL",
      "metadata": {
        "id": "nJC69pyUZhOL"
      },
      "outputs": [],
      "source": [
        "# Loss functions\n",
        "\n",
        "type_loss_fct = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
        "polarity_loss_fct = nn.CrossEntropyLoss()\n",
        "intensity_loss_fct = nn.BCEWithLogitsLoss()\n",
        "\n",
        "def get_losses(logits, labels, batch_size):\n",
        "    type_logits = logits[:, :NUM_TYPE_CLASSES]\n",
        "    polarity_logits = [ # [NUM_TYPE_CLASSES, batch_size, NUM_POLARITY_CLASSES]\n",
        "        logits[:,\n",
        "            NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+0:\n",
        "            NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+3\n",
        "        ] for i in range(NUM_TYPE_CLASSES)\n",
        "    ]\n",
        "    intensity_logits = [ # [NUM_TYPE_CLASSES, batch_size, NUM_INTENSITY_CLASSES]\n",
        "        logits[:,\n",
        "            NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+3:\n",
        "            NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+6\n",
        "        ] for i in range(NUM_TYPE_CLASSES)\n",
        "    ]\n",
        "\n",
        "    type_targets = labels[:, :NUM_TYPE_CLASSES]\n",
        "    polarity_targets = [\n",
        "        labels[:,\n",
        "            NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+0:\n",
        "            NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+3\n",
        "        ] for i in range(NUM_TYPE_CLASSES)\n",
        "    ]\n",
        "    intensity_targets = [\n",
        "        labels[:,\n",
        "            NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+3:\n",
        "            NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+6\n",
        "        ] for i in range(NUM_TYPE_CLASSES)\n",
        "    ]\n",
        "\n",
        "    type_loss = type_loss_fct(type_logits, type_targets)\n",
        "\n",
        "    polarity_loss = 0\n",
        "    for batch_i in range(batch_size):\n",
        "        for i in range(NUM_TYPE_CLASSES):\n",
        "            polarity_loss += type_targets[batch_i, i] * polarity_loss_fct(polarity_logits[i][batch_i], polarity_targets[i][batch_i])\n",
        "    if DIVIDE_LOSS_BY == 'batch size':\n",
        "        polarity_loss = polarity_loss / batch_size\n",
        "    elif DIVIDE_LOSS_BY == 'number of annotations':\n",
        "        polarity_loss = polarity_loss / torch.sum(type_targets)\n",
        "\n",
        "    intensity_loss = 0\n",
        "    for batch_i in range(batch_size):\n",
        "        for i in range(NUM_TYPE_CLASSES):\n",
        "            intensity_loss += type_targets[batch_i, i] * intensity_loss_fct(intensity_logits[i][batch_i], intensity_targets[i][batch_i])\n",
        "    if DIVIDE_LOSS_BY == 'batch size':\n",
        "        intensity_loss = intensity_loss / batch_size\n",
        "    elif DIVIDE_LOSS_BY == 'number of annotations':\n",
        "        intensity_loss = intensity_loss / torch.sum(type_targets)\n",
        "\n",
        "    return type_loss, polarity_loss, intensity_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vkaY6Wz0Z238",
      "metadata": {
        "id": "vkaY6Wz0Z238"
      },
      "outputs": [],
      "source": [
        "# Custom Model\n",
        "\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "\n",
        "class CustomModel(nn.Module):\n",
        "    def __init__(self, model_hf):\n",
        "        super(CustomModel,self).__init__()\n",
        "        self.model = model_hf\n",
        "        self.classifier = nn.Linear(768, 35) # load and initialize weights\n",
        "\n",
        "    def forward(self, input_ids=None, token_type_ids=None, attention_mask=None, labels=None):\n",
        "        batch_size = len(input_ids)\n",
        "        # Extract outputs from the body\n",
        "        bert_output = self.model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        bert_output = bert_output[0] # last hidden state with the shape of (batch_size, sequence_length, hidden_size)\n",
        "        CLS = bert_output[:, 0, :].view(-1,768) # Use [CLS] token\n",
        "\n",
        "        logits = self.classifier(CLS)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            type_loss, polarity_loss, intensity_loss = get_losses(logits, labels, batch_size)\n",
        "            if RANDOM_ASYNCHRONOUS_MTL == False:\n",
        "                loss = ALPHA_TYPE * type_loss + ALPHA_POLARITY * polarity_loss + ALPHA_INTENSITY * intensity_loss\n",
        "            else:\n",
        "                random_task_selector = (ALPHA_TYPE + ALPHA_POLARITY + ALPHA_INTENSITY) * random.random()\n",
        "                if random_task_selector < ALPHA_TYPE:\n",
        "                    loss = type_loss\n",
        "                elif random_task_selector < ALPHA_TYPE + ALPHA_POLARITY:\n",
        "                    loss = polarity_loss\n",
        "                else: # if random_task_selector < ALPHA_TYPE + ALPHA_POLARITY + ALPHA_INTENSITY\n",
        "                    loss = intensity_loss\n",
        "\n",
        "        return SequenceClassifierOutput(loss=loss, logits=logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4r8aXewtHfUk",
      "metadata": {
        "id": "4r8aXewtHfUk"
      },
      "outputs": [],
      "source": [
        "model_hf = load_model_hf()\n",
        "model = CustomModel(model_hf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "M84ls4FDWqxG",
      "metadata": {
        "id": "M84ls4FDWqxG"
      },
      "outputs": [],
      "source": [
        "# Create temp dataloader to help showing model's summary\n",
        "\n",
        "X_temp_text, X_temp_head = X[:1, 0].tolist(), X[:1, 1].tolist()\n",
        "y_temp = y.tolist()[:1]\n",
        "X_temp_tokenized = tokenize_inputs(X_temp_text, X_temp_head)\n",
        "temp_dataset = get_dataset(X_temp_tokenized, y_temp)\n",
        "temp_dataloader = get_dataloader(temp_dataset, batch_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jcaGCPhT8qD9",
      "metadata": {
        "id": "jcaGCPhT8qD9"
      },
      "outputs": [],
      "source": [
        "# Show model's summary\n",
        "\n",
        "from torchinfo import summary\n",
        "\n",
        "for batch in temp_dataloader:\n",
        "    batch = {k: v for k, v in batch.items() if k != 'labels'}\n",
        "    break\n",
        "\n",
        "summary(model, input_data=batch, device='cpu', dtypes=['torch.IntTensor'], depth=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qc3Ifox5E4_j",
      "metadata": {
        "id": "qc3Ifox5E4_j"
      },
      "source": [
        "# Metrics and Training Arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_v4OXGINaQyV",
      "metadata": {
        "id": "_v4OXGINaQyV"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Yl3QvG6aaQhG",
      "metadata": {
        "id": "Yl3QvG6aaQhG"
      },
      "outputs": [],
      "source": [
        "def calculate_losses(preds, targets, decimals=6):\n",
        "    batch_size = len(preds)\n",
        "    logits = torch.from_numpy(preds).cuda()\n",
        "    labels = torch.from_numpy(targets).type(torch.float).cuda()\n",
        "\n",
        "    type_loss, polarity_loss, intensity_loss = get_losses(logits, labels, batch_size)\n",
        "\n",
        "    type_loss  = type_loss.cpu().numpy().copy()  * ALPHA_TYPE\n",
        "    polarity_loss  = polarity_loss.cpu().numpy().copy()  * ALPHA_POLARITY\n",
        "    intensity_loss = intensity_loss.cpu().numpy().copy() * ALPHA_INTENSITY\n",
        "\n",
        "    losses = {}\n",
        "    if ALPHA_TYPE > 0:\n",
        "        losses['type_cost'] = np.round(type_loss,  decimals)\n",
        "    if ALPHA_POLARITY > 0:\n",
        "        losses['polarity_cost'] = np.round(polarity_loss,  decimals)\n",
        "    if ALPHA_INTENSITY > 0:\n",
        "        losses['intensity_cost'] = np.round(intensity_loss,  decimals)\n",
        "\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XN_RQA6laWIG",
      "metadata": {
        "id": "XN_RQA6laWIG"
      },
      "outputs": [],
      "source": [
        "def calculate_type_metrics(preds, targets, decimals=6):\n",
        "    targets = targets[:, :NUM_TYPE_CLASSES]\n",
        "    preds   = preds[:, :NUM_TYPE_CLASSES]\n",
        "\n",
        "    preds = sigmoid(preds)\n",
        "    preds = np.array(preds > TYPE_THRESHOLD, dtype=int)\n",
        "\n",
        "    accuracy_list = np.sum(preds == targets, axis=0).astype(float) / preds.shape[0]\n",
        "    f1_list = f1_score(y_true=targets, y_pred=preds, zero_division=0, average=None)\n",
        "    precision_list = precision_score(y_true=targets, y_pred=preds, zero_division=0, average=None)\n",
        "    recall_list = recall_score(y_true=targets, y_pred=preds, zero_division=0, average=None)\n",
        "\n",
        "    TP = np.sum(preds & targets)\n",
        "    FP = np.sum(preds & (1-targets))\n",
        "    FN = np.sum((1-preds) & targets)\n",
        "\n",
        "    micro_precision = TP / (TP + FP)\n",
        "    micro_recall = TP / (TP + FN)\n",
        "    micro_f1 = statistics.harmonic_mean([micro_precision, micro_recall])\n",
        "    micro_accuracy = np.mean(preds == targets)\n",
        "\n",
        "    exact_match_ratio = np.mean(np.sum(preds == targets, axis = 1) == NUM_TYPE_CLASSES) # The percentage of samples that have all their labels classified correctly\n",
        "\n",
        "    return {\n",
        "        'type_exact_match_ratio': np.round(exact_match_ratio, decimals),\n",
        "        'type_micro_f1': np.round(micro_f1, decimals),\n",
        "        'type_micro_precision': np.round(micro_precision, decimals),\n",
        "        'type_micro_recall': np.round(micro_recall, decimals),\n",
        "        'type_micro_accuracy': np.round(np.mean(micro_accuracy), decimals),\n",
        "        'type_f1': np.round(f1_list, decimals).tolist(),\n",
        "        'type_precision': np.round(precision_list, decimals).tolist(),\n",
        "        'type_recall': np.round(recall_list, decimals).tolist(),\n",
        "        'type_accuracy': np.round(accuracy_list, decimals).tolist(),\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HOVez_ANQ79z",
      "metadata": {
        "id": "HOVez_ANQ79z"
      },
      "outputs": [],
      "source": [
        "def calculate_polarity_f1_measure(extracted_polarity_preds, extracted_polarity_targets):\n",
        "    extracted_polarity_targets = np.argmax(extracted_polarity_targets, axis=-1)\n",
        "    extracted_polarity_preds   = np.argmax(extracted_polarity_preds,   axis=-1)\n",
        "    polarity_weighted_f1 = f1_score(extracted_polarity_targets, extracted_polarity_preds, average='weighted')\n",
        "    return polarity_weighted_f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7F1SuOxLaYRY",
      "metadata": {
        "id": "7F1SuOxLaYRY"
      },
      "outputs": [],
      "source": [
        "def calculate_polarity_correctness_score(extracted_polarity_preds, extracted_polarity_targets):\n",
        "    extracted_polarity_targets = np.argmax(extracted_polarity_targets, axis=-1)\n",
        "    extracted_polarity_preds   = np.argmax(extracted_polarity_preds,   axis=-1)\n",
        "    polarity_score = np.sum(extracted_polarity_preds == extracted_polarity_targets)\n",
        "    return polarity_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aTrmgODvD5Y_",
      "metadata": {
        "id": "aTrmgODvD5Y_"
      },
      "outputs": [],
      "source": [
        "def calculate_pipeline_polarity_correctness_score(extracted_polarity_preds, extracted_polarity_targets, correctly_predicted_types):\n",
        "    extracted_polarity_targets = np.argmax(extracted_polarity_targets, axis=-1)\n",
        "    extracted_polarity_preds   = np.argmax(extracted_polarity_preds,   axis=-1)\n",
        "    polarity_score = np.sum((extracted_polarity_preds == extracted_polarity_targets) * correctly_predicted_types)\n",
        "    return polarity_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dzNgqFOraaXS",
      "metadata": {
        "id": "dzNgqFOraaXS"
      },
      "outputs": [],
      "source": [
        "def calculate_polarity_metrics(preds, targets, decimals=6):\n",
        "    batch_size = len(preds)\n",
        "\n",
        "    type_targets = targets[:, :NUM_TYPE_CLASSES]\n",
        "    type_preds   = sigmoid(preds[:, :NUM_TYPE_CLASSES]) > TYPE_THRESHOLD\n",
        "\n",
        "    polarity_targets = [ # [NUM_TYPE_CLASSES, batch_size, NUM_POLARITY_CLASSES]\n",
        "        targets[:,\n",
        "            NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+0:\n",
        "            NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+3\n",
        "        ] for i in range(NUM_TYPE_CLASSES)\n",
        "    ]\n",
        "    filtered_preds = [] # Make every polarity of non expressive-subjectivities equal to a negative number\n",
        "    for j in range(len(preds)):\n",
        "        filtered_pred = preds[j, :]\n",
        "        for i in range(NUM_TYPE_CLASSES):\n",
        "            if i != type_classname2classid['expressive_subjectivity']:\n",
        "                filtered_pred[NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+1] = -1 + min(\n",
        "                    filtered_pred[NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+0],\n",
        "                    filtered_pred[NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+2]\n",
        "                )\n",
        "        filtered_preds.append(np.array(filtered_pred))\n",
        "    filtered_preds = np.array(filtered_preds)\n",
        "    polarity_preds = [ # [NUM_TYPE_CLASSES, batch_size, NUM_POLARITY_CLASSES]\n",
        "        filtered_preds[:,\n",
        "            NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+0:\n",
        "            NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+3\n",
        "        ] for i in range(NUM_TYPE_CLASSES)\n",
        "    ]\n",
        "\n",
        "    extracted_polarity_targets = []\n",
        "    extracted_polarity_preds   = []\n",
        "    correctly_predicted_types   = []\n",
        "    for batch_i in range(batch_size):\n",
        "        for type_i in range(NUM_TYPE_CLASSES):\n",
        "            if type_targets[batch_i, type_i] == 1:\n",
        "                extracted_polarity_targets.append(polarity_targets[type_i][batch_i])\n",
        "                extracted_polarity_preds.append(polarity_preds[type_i][batch_i])\n",
        "                correctly_predicted_types.append(1 if type_preds[batch_i, type_i] else 0)\n",
        "    extracted_polarity_targets = np.array(extracted_polarity_targets) # [np.sum(type_targets), NUM_polarity_CLASSES]\n",
        "    extracted_polarity_preds   = np.array(extracted_polarity_preds)   # [np.sum(type_targets), NUM_polarity_CLASSES]\n",
        "    correctly_predicted_types  = np.array(correctly_predicted_types)  # [np.sum(type_targets)]\n",
        "\n",
        "    polarity_acc = calculate_polarity_correctness_score(extracted_polarity_preds, extracted_polarity_targets) / np.sum(type_targets)\n",
        "    polarity_weighted_f1 = calculate_polarity_f1_measure(extracted_polarity_preds, extracted_polarity_targets)\n",
        "\n",
        "    metrics = {\n",
        "        'polarity_accuracy': np.round(polarity_acc, decimals),\n",
        "        'polarity_weighted_f1': np.round(polarity_weighted_f1, decimals),\n",
        "    }\n",
        "\n",
        "    if ALPHA_TYPE == 0 or ALPHA_POLARITY == 0 or ALPHA_INTENSITY == 0:\n",
        "        polarity_pipeline_acc = 0\n",
        "    else:\n",
        "        polarity_pipeline_acc = calculate_pipeline_polarity_correctness_score(extracted_polarity_preds, extracted_polarity_targets, correctly_predicted_types) / np.sum(type_targets)\n",
        "        metrics['polarity_pipeline_accuracy'] = np.round(polarity_pipeline_acc, decimals)\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LSCwUeD3ZbF8",
      "metadata": {
        "id": "LSCwUeD3ZbF8"
      },
      "outputs": [],
      "source": [
        "# Convert 3-dim intensity vector to its corresponding number\n",
        "\n",
        "def get_intensity_id(vec):\n",
        "    vec = vec.tolist()\n",
        "    if vec == [1, 0, 0]:\n",
        "        return 0\n",
        "    if vec == [1, 1, 0]:\n",
        "        return 1\n",
        "    if vec == [0, 1, 0]:\n",
        "        return 2\n",
        "    if vec == [0, 1, 1]:\n",
        "        return 3\n",
        "    if vec == [0, 0, 1]:\n",
        "        return 4\n",
        "    return 1 # everything is equal to low-medium by default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sbu9FBLhU0QQ",
      "metadata": {
        "id": "sbu9FBLhU0QQ"
      },
      "outputs": [],
      "source": [
        "def calculate_intensity_d_correctness_score(extracted_intensity_preds, extracted_intensity_targets, d=1):\n",
        "    batch_size = len(extracted_intensity_preds)\n",
        "    intensity_score = 0\n",
        "    for i in range(batch_size):\n",
        "        target_id = get_intensity_id(extracted_intensity_targets[i]) # everything is equal to low-medium by default\n",
        "        pred_id   = get_intensity_id(extracted_intensity_preds[i])   # everything is equal to low-medium by default\n",
        "        if abs(target_id - pred_id) <= d:\n",
        "            intensity_score += 1\n",
        "    return intensity_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Q7HY-OB2-FhI",
      "metadata": {
        "id": "Q7HY-OB2-FhI"
      },
      "outputs": [],
      "source": [
        "def calculate_intensity_f1_measure(extracted_intensity_preds, extracted_intensity_targets):\n",
        "\n",
        "    whole = 1.0\n",
        "    with_penalty = 0\n",
        "    half_false = 1\n",
        "    thresh = 0.5\n",
        "    trues = {'medium': 0, 'medium-high': 0, 'low': 0, 'high': 0, 'low-medium': 0}  # TP\n",
        "    cnt = {'medium': 0, 'medium-high': 0, 'low': 0, 'high': 0, 'low-medium': 0}    # TP + FN\n",
        "    falses = {'medium': 0, 'medium-high': 0, 'low': 0, 'high': 0, 'low-medium': 0} # FP\n",
        "\n",
        "    preds_indices = np.argmax(extracted_intensity_preds, axis=-1)\n",
        "\n",
        "    for i in range(len(preds_indices)):\n",
        "\n",
        "        if preds_indices[i] == 0:\n",
        "            if extracted_intensity_targets[i][0] == 0 and  extracted_intensity_targets[i][1] == 0 and  extracted_intensity_targets[i][2] == 1:\n",
        "                falses['low'] += 1\n",
        "            if extracted_intensity_targets[i][0] == 0 and  extracted_intensity_targets[i][1] == 1 and  extracted_intensity_targets[i][2] == 0:\n",
        "                falses['low'] += half_false\n",
        "            if extracted_intensity_targets[i][0] == 0 and  extracted_intensity_targets[i][1] == 1 and  extracted_intensity_targets[i][2] == 1:\n",
        "                falses['low'] += half_false\n",
        "\n",
        "        if preds_indices[i] == 1:\n",
        "            if extracted_intensity_targets[i][0] == 0 and  extracted_intensity_targets[i][1] == 0 and  extracted_intensity_targets[i][2] == 1:\n",
        "                falses['medium'] += half_false\n",
        "            if extracted_intensity_targets[i][0] == 1 and  extracted_intensity_targets[i][1] == 0 and  extracted_intensity_targets[i][2] == 0:\n",
        "                falses['medium'] += half_false\n",
        "\n",
        "        if preds_indices[i] == 2:\n",
        "            if extracted_intensity_targets[i][0] == 1 and  extracted_intensity_targets[i][1] == 0 and  extracted_intensity_targets[i][2] == 0:\n",
        "                falses['high'] += 1\n",
        "            if extracted_intensity_targets[i][0] == 1 and  extracted_intensity_targets[i][1] == 1 and  extracted_intensity_targets[i][2] == 0:\n",
        "                falses['high'] += 1\n",
        "            if extracted_intensity_targets[i][0] == 0 and  extracted_intensity_targets[i][1] == 1 and  extracted_intensity_targets[i][2] == 1:\n",
        "                falses['high'] += half_false\n",
        "            if extracted_intensity_targets[i][0] == 0 and  extracted_intensity_targets[i][1] == 1 and  extracted_intensity_targets[i][2] == 0:\n",
        "                falses['high'] += half_false\n",
        "\n",
        "        if extracted_intensity_targets[i][0] == 1 and  extracted_intensity_targets[i][1] == 0 and  extracted_intensity_targets[i][2] == 0:\n",
        "            cnt['low'] += 1\n",
        "            if preds_indices[i] == 0:\n",
        "                trues['low'] += whole\n",
        "\n",
        "        elif extracted_intensity_targets[i][0] == 0 and  extracted_intensity_targets[i][1] == 1 and  extracted_intensity_targets[i][2] == 0:\n",
        "            cnt['medium'] += 1\n",
        "            if preds_indices[i] == 1:\n",
        "                trues['medium'] += whole\n",
        "            else:\n",
        "                trues['medium'] += with_penalty\n",
        "\n",
        "        elif extracted_intensity_targets[i][0] == 0 and  extracted_intensity_targets[i][1] == 0 and  extracted_intensity_targets[i][2] == 1:\n",
        "            cnt['high'] += 1\n",
        "            if preds_indices[i] == 2:\n",
        "                trues['high'] += whole\n",
        "\n",
        "        elif extracted_intensity_targets[i][0] == 1 and  extracted_intensity_targets[i][1] == 1 and  extracted_intensity_targets[i][2] == 0:\n",
        "            cnt['low-medium'] += 1\n",
        "            if preds_indices[i] == 0 or preds_indices[i] == 1:\n",
        "                trues['low-medium'] += whole\n",
        "\n",
        "        elif extracted_intensity_targets[i][0] == 0 and  extracted_intensity_targets[i][1] == 1 and  extracted_intensity_targets[i][2] == 1:\n",
        "            cnt['medium-high'] += 1\n",
        "            if preds_indices[i] == 1 or preds_indices[i] == 2:\n",
        "                trues['medium-high'] += whole\n",
        "\n",
        "    weighted_f1 = 0\n",
        "    weights = 0\n",
        "    for intensity_class in trues.keys():\n",
        "        try:\n",
        "            intensity_class_precision = trues[intensity_class] / (trues[intensity_class] + falses[intensity_class])\n",
        "        except:\n",
        "            intensity_class_precision = 1\n",
        "        try:\n",
        "            intensity_class_recall = trues[intensity_class] / cnt[intensity_class]\n",
        "        except:\n",
        "            intensity_class_recall = 1\n",
        "        intensity_class_f1 = statistics.harmonic_mean([intensity_class_precision, intensity_class_recall])\n",
        "        weighted_f1 += intensity_class_f1 * cnt[intensity_class]\n",
        "        weights += cnt[intensity_class]\n",
        "    intensity_weighted_f1 = weighted_f1 / weights\n",
        "\n",
        "    return intensity_weighted_f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bl-rW6LfacIX",
      "metadata": {
        "id": "bl-rW6LfacIX"
      },
      "outputs": [],
      "source": [
        "def calculate_intensity_correctness_score(extracted_intensity_preds, extracted_intensity_targets):\n",
        "    extracted_intensity_preds_argmax = np.argmax(extracted_intensity_preds, axis=-1)\n",
        "    intensity_score = 0\n",
        "    for i in range(len(extracted_intensity_preds_argmax)):\n",
        "        if (extracted_intensity_targets[i, extracted_intensity_preds_argmax[i]] == 1):\n",
        "            intensity_score += 1\n",
        "    return intensity_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "heRILuHg9DjH",
      "metadata": {
        "id": "heRILuHg9DjH"
      },
      "outputs": [],
      "source": [
        "def calculate_pipeline_intensity_correctness_score(extracted_intensity_preds, extracted_intensity_targets, correctly_predicted_types):\n",
        "    extracted_intensity_preds_argmax = np.argmax(extracted_intensity_preds, axis=-1)\n",
        "    intensity_score = 0\n",
        "    for i in range(len(extracted_intensity_preds_argmax)):\n",
        "        if correctly_predicted_types[i] and (extracted_intensity_targets[i, extracted_intensity_preds_argmax[i]] == 1):\n",
        "            intensity_score += 1\n",
        "    return intensity_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pmzE32JJafGz",
      "metadata": {
        "id": "pmzE32JJafGz"
      },
      "outputs": [],
      "source": [
        "def calculate_intensity_metrics(preds, targets, decimals=6):\n",
        "    batch_size = len(preds)\n",
        "\n",
        "    type_targets = targets[:, :NUM_TYPE_CLASSES]\n",
        "    type_preds   = sigmoid(preds[:, :NUM_TYPE_CLASSES]) > TYPE_THRESHOLD\n",
        "    intensity_targets = [ # [NUM_TYPE_CLASSES, batch_size, NUM_POLARITY_CLASSES]\n",
        "        targets[:,\n",
        "            NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+3:\n",
        "            NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+6\n",
        "        ] for i in range(NUM_TYPE_CLASSES)\n",
        "    ]\n",
        "    intensity_preds = [ # [NUM_TYPE_CLASSES, batch_size, NUM_POLARITY_CLASSES]\n",
        "        preds[:,\n",
        "            NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+3:\n",
        "            NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+6\n",
        "        ] for i in range(NUM_TYPE_CLASSES)\n",
        "    ]\n",
        "\n",
        "    extracted_intensity_targets = []\n",
        "    extracted_intensity_preds   = []\n",
        "    correctly_predicted_types   = []\n",
        "    for batch_i in range(batch_size):\n",
        "        for type_i in range(NUM_TYPE_CLASSES):\n",
        "            if type_targets[batch_i, type_i] == 1:\n",
        "                extracted_intensity_targets.append(intensity_targets[type_i][batch_i])\n",
        "                extracted_intensity_preds.append(intensity_preds[type_i][batch_i])\n",
        "                correctly_predicted_types.append(1 if type_preds[batch_i, type_i] else 0)\n",
        "    extracted_intensity_targets = np.array(extracted_intensity_targets) # [np.sum(type_targets), NUM_INTENSITY_CLASSES]\n",
        "    extracted_intensity_preds   = np.array(extracted_intensity_preds)   # [np.sum(type_targets), NUM_INTENSITY_CLASSES]\n",
        "    correctly_predicted_types   = np.array(correctly_predicted_types)   # [np.sum(type_targets)]\n",
        "\n",
        "    number_of_samples = np.sum(type_targets)\n",
        "    intensity_d0_acc = calculate_intensity_d_correctness_score(extracted_intensity_preds, extracted_intensity_targets, d=0) / number_of_samples\n",
        "    intensity_d1_acc = calculate_intensity_d_correctness_score(extracted_intensity_preds, extracted_intensity_targets, d=1) / number_of_samples\n",
        "    intensity_d2_acc = calculate_intensity_d_correctness_score(extracted_intensity_preds, extracted_intensity_targets, d=2) / number_of_samples\n",
        "    intensity_d3_acc = calculate_intensity_d_correctness_score(extracted_intensity_preds, extracted_intensity_targets, d=3) / number_of_samples\n",
        "    intensity_d4_acc = calculate_intensity_d_correctness_score(extracted_intensity_preds, extracted_intensity_targets, d=4) / number_of_samples\n",
        "    intensity_acc    = calculate_intensity_correctness_score(extracted_intensity_preds, extracted_intensity_targets)        / number_of_samples\n",
        "    intensity_weighted_f1 = calculate_intensity_f1_measure(extracted_intensity_preds, extracted_intensity_targets)\n",
        "\n",
        "    metrics = {\n",
        "        'intensity_exact_match_ratio': np.round(intensity_d0_acc, decimals),\n",
        "        'intensity_d1_accuracy': np.round(intensity_d1_acc, decimals),\n",
        "        'intensity_d2_accuracy': np.round(intensity_d2_acc, decimals),\n",
        "        'intensity_d3_accuracy': np.round(intensity_d3_acc, decimals),\n",
        "        'intensity_d4_accuracy': np.round(intensity_d4_acc, decimals),\n",
        "        'intensity_accuracy': np.round(intensity_acc, decimals),\n",
        "        'intensity_weighted_f1': np.round(intensity_weighted_f1, decimals),\n",
        "    }\n",
        "\n",
        "    if ALPHA_TYPE == 0 or ALPHA_POLARITY == 0 or ALPHA_INTENSITY == 0:\n",
        "        intensity_pipeline_acc = 0\n",
        "    else:\n",
        "        intensity_pipeline_acc = calculate_pipeline_intensity_correctness_score(extracted_intensity_preds, extracted_intensity_targets, correctly_predicted_types) / np.sum(type_targets)\n",
        "        metrics['intensity_pipeline_accuracy'] = np.round(intensity_pipeline_acc, decimals)\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ou_r9sNHahNV",
      "metadata": {
        "id": "Ou_r9sNHahNV"
      },
      "outputs": [],
      "source": [
        "def calculate_general_metrics(preds, targets, decimals=6):\n",
        "    batch_size = len(preds)\n",
        "\n",
        "    type_targets = targets[:, :NUM_TYPE_CLASSES]\n",
        "    polarity_targets = [ # [NUM_TYPE_CLASSES, batch_size, NUM_POLARITY_CLASSES]\n",
        "        targets[:,\n",
        "            NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+0:\n",
        "            NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+3\n",
        "        ] for i in range(NUM_TYPE_CLASSES)\n",
        "    ]\n",
        "    intensity_targets = [ # [NUM_TYPE_CLASSES, batch_size, NUM_POLARITY_CLASSES]\n",
        "        targets[:,\n",
        "            NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+3:\n",
        "            NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+6\n",
        "        ] for i in range(NUM_TYPE_CLASSES)\n",
        "    ]\n",
        "\n",
        "    type_preds = sigmoid(preds[:, :NUM_TYPE_CLASSES]) > TYPE_THRESHOLD\n",
        "    polarity_preds = [ # [NUM_TYPE_CLASSES, batch_size, NUM_POLARITY_CLASSES]\n",
        "        preds[:,\n",
        "            NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+0:\n",
        "            NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+3\n",
        "        ] for i in range(NUM_TYPE_CLASSES)\n",
        "    ]\n",
        "    intensity_preds = [ # [NUM_TYPE_CLASSES, batch_size, NUM_POLARITY_CLASSES]\n",
        "        preds[:,\n",
        "            NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+3:\n",
        "            NUM_TYPE_CLASSES+(NUM_POLARITY_CLASSES+NUM_INTENSITY_CLASSES)*i+6\n",
        "        ] for i in range(NUM_TYPE_CLASSES)\n",
        "    ]\n",
        "\n",
        "    custom_accuracy = 0\n",
        "    exact_match_ratio = 0\n",
        "    for batch_i in range(batch_size):\n",
        "        exact_match_ratio_flag = True\n",
        "        for type_i in range(NUM_TYPE_CLASSES):\n",
        "            if type_preds[batch_i, type_i] == 1 and type_targets[batch_i, type_i] == 1:\n",
        "                type_correctness_score  = 1\n",
        "                polarity_correctness_score  = calculate_polarity_correctness_score(polarity_preds[type_i][batch_i:batch_i+1], polarity_targets[type_i][batch_i:batch_i+1])\n",
        "                intensity_correctness_score = calculate_intensity_correctness_score(intensity_preds[type_i][batch_i:batch_i+1], intensity_targets[type_i][batch_i:batch_i+1])\n",
        "                if (polarity_correctness_score < 1 or intensity_correctness_score < 1):\n",
        "                    exact_match_ratio_flag = False\n",
        "                custom_accuracy += (type_correctness_score/3 + polarity_correctness_score/3 + intensity_correctness_score/3) / NUM_TYPE_CLASSES\n",
        "            elif type_preds[batch_i, type_i] == 0 and type_targets[batch_i, type_i] == 0:\n",
        "                type_correctness_score = 1\n",
        "                custom_accuracy += type_correctness_score / NUM_TYPE_CLASSES\n",
        "            else:\n",
        "                exact_match_ratio_flag = False\n",
        "\n",
        "        if exact_match_ratio_flag == True:\n",
        "            exact_match_ratio += 1\n",
        "\n",
        "    custom_accuracy = custom_accuracy / batch_size\n",
        "    exact_match_ratio = exact_match_ratio / batch_size\n",
        "\n",
        "    return {\n",
        "        'custom_accuracy': np.round(custom_accuracy, decimals), # No points for wrong annotation type predictions and 1/5 for each correct negative annotation type predicitions and 1/15 of a point for each correct positive annotation type, polarity or intensity prediction\n",
        "        'exact_match_ratio': np.round(exact_match_ratio, decimals), # All annotation types and their corresponding polarities and intensities of each sample gotta be correct\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Romelqk1ajX-",
      "metadata": {
        "id": "Romelqk1ajX-"
      },
      "outputs": [],
      "source": [
        "def calculate_metrics(pred):\n",
        "    targets = np.array(pred.label_ids, dtype=int)\n",
        "    preds   = pred.predictions\n",
        "    n_tasks = 0\n",
        "\n",
        "    metrics = {**calculate_losses(preds, targets)}\n",
        "    sum = 0.0\n",
        "\n",
        "    if ALPHA_POLARITY > 0:\n",
        "        metrics.update(calculate_polarity_metrics(preds, targets))\n",
        "        sum += metrics['polarity_accuracy']\n",
        "        n_tasks += 1\n",
        "\n",
        "    if ALPHA_INTENSITY > 0:\n",
        "        metrics.update(calculate_intensity_metrics(preds, targets))\n",
        "        sum += metrics['intensity_accuracy']\n",
        "        n_tasks += 1\n",
        "\n",
        "    if ALPHA_TYPE > 0:\n",
        "        metrics.update(calculate_type_metrics(preds, targets))\n",
        "        sum += metrics['type_micro_f1']\n",
        "        n_tasks += 1\n",
        "\n",
        "    if ALPHA_TYPE > 0 and ALPHA_POLARITY > 0 and ALPHA_INTENSITY > 0:\n",
        "        metrics.update(calculate_general_metrics(preds, targets))\n",
        "\n",
        "    metrics['average_of_metrics'] = np.round(sum/n_tasks, 6)\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dfde22e-6ec5-409d-9d5f-bafb21d8d0e9",
      "metadata": {
        "id": "2dfde22e-6ec5-409d-9d5f-bafb21d8d0e9"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QdusgCNayB0B",
      "metadata": {
        "id": "QdusgCNayB0B"
      },
      "outputs": [],
      "source": [
        "# Training Arguments\n",
        "\n",
        "def get_training_args(fold_counter):\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir = f'models/{EXPERIMENT_NAME}_{fold_counter}',\n",
        "        overwrite_output_dir = True,\n",
        "        per_device_train_batch_size = TRAIN_BATCH_SIZE,\n",
        "        per_device_eval_batch_size = VAL_BATCH_SIZE,\n",
        "        local_rank = LOCAL_RANK,\n",
        "        fp16 = FP16,\n",
        "        fp16_opt_level = FP16_OPT_LEVEL,\n",
        "        evaluation_strategy = EVAL_STRATEGY,\n",
        "        logging_steps = LOGGING_STEPS,\n",
        "        save_strategy = SAVE_STRATEGY,\n",
        "        save_steps = LOGGING_STEPS,\n",
        "        save_total_limit = 1,\n",
        "        num_train_epochs = NUM_TRAIN_EPOCHS,\n",
        "        load_best_model_at_end = LOAD_BEST_MODEL_AT_END,\n",
        "        metric_for_best_model = METRIC_FOR_BEST_MODEL,\n",
        "        dataloader_num_workers = NUM_WORKERS,\n",
        "        seed = SEED,\n",
        "        group_by_length=True,\n",
        "        report_to = \"none\",\n",
        "        full_determinism=True\n",
        "    )\n",
        "    print(\"Number of GPUs:\", training_args.n_gpu)\n",
        "    print(\"Parallel Mode:\", training_args.parallel_mode)\n",
        "    return training_args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7705257c-d00c-4257-9f91-f1bfd918776a",
      "metadata": {
        "id": "7705257c-d00c-4257-9f91-f1bfd918776a"
      },
      "outputs": [],
      "source": [
        "# Setup trainer\n",
        "\n",
        "def setup_trainer(model, train_dataset, val_dataset, optimizer, fold_counter):\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    training_args = get_training_args(fold_counter)\n",
        "    trainer = Trainer(\n",
        "        model = model,\n",
        "        args = training_args,\n",
        "        optimizers = (optimizer, None),\n",
        "        train_dataset = train_dataset,\n",
        "        eval_dataset = val_dataset,\n",
        "        data_collator = data_collator,\n",
        "        compute_metrics = calculate_metrics,\n",
        "        callbacks = CALLBACKS\n",
        "    )\n",
        "    return trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "n1F5NUhkJ2bf",
      "metadata": {
        "id": "n1F5NUhkJ2bf"
      },
      "outputs": [],
      "source": [
        "# Train\n",
        "\n",
        "folds_train_log          = []\n",
        "folds_val_log            = []\n",
        "folds_test_log           = []\n",
        "\n",
        "for fold_counter in range(0, min(len(FOLDS), MAX_FOLDS)):\n",
        "\n",
        "    print(f'\\n\\033[1mFold {fold_counter+1}:\\033[0m')\n",
        "\n",
        "    set_seed()\n",
        "\n",
        "    fold_keys = FOLDS[fold_counter]\n",
        "    train_ids = csds_splits[fold_keys[0]]\n",
        "    val_ids   = csds_splits[fold_keys[1]]\n",
        "    test_ids  = csds_splits[fold_keys[2]]\n",
        "\n",
        "    train_objects, val_objects, test_objects = filter_csds_objects_all(csds_objects, train_ids, val_ids, test_ids)\n",
        "\n",
        "    train_input_target_dict, n_train_samples = prepare_inputs_and_targets(train_objects)\n",
        "    val_input_target_dict,   n_val_samples   = prepare_inputs_and_targets(val_objects)\n",
        "    test_input_target_dict,  n_test_samples  = prepare_inputs_and_targets(test_objects)\n",
        "\n",
        "    X_train = np.array(list(train_input_target_dict.keys()))\n",
        "    X_val = np.array(list(val_input_target_dict.keys()))\n",
        "    X_test = np.array(list(test_input_target_dict.keys()))\n",
        "\n",
        "    y_train = list(train_input_target_dict.values())\n",
        "    y_val = list(val_input_target_dict.values())\n",
        "    y_test = list(test_input_target_dict.values())\n",
        "\n",
        "    X_train_text, X_train_head = X_train[:, 0].tolist(), X_train[:, 1].tolist()\n",
        "    X_val_text, X_val_head = X_val[:, 0].tolist(), X_val[:, 1].tolist()\n",
        "    X_test_text, X_test_head = X_test[:, 0].tolist(), X_test[:, 1].tolist()\n",
        "\n",
        "    n_samples = n_train_samples + n_val_samples + n_test_samples\n",
        "    print(f'Train set size:      {n_train_samples} \\t({100*n_train_samples/n_samples}%)')\n",
        "    print(f'Validation set size: {n_val_samples} \\t({100*n_val_samples/n_samples}%)')\n",
        "    print(f'Test set size:       {n_test_samples} \\t({100*n_test_samples/n_samples}%)')\n",
        "\n",
        "    X_train_tokenized = tokenize_inputs(X_train_text, X_train_head)\n",
        "    X_val_tokenized   = tokenize_inputs(X_val_text,   X_val_head  )\n",
        "    X_test_tokenized  = tokenize_inputs(X_test_text,  X_test_head )\n",
        "\n",
        "    train_dataset = get_dataset(X_train_tokenized, y_train)\n",
        "    val_dataset   = get_dataset(X_val_tokenized,   y_val  )\n",
        "    test_dataset  = get_dataset(X_test_tokenized,  y_test )\n",
        "\n",
        "    model_hf = load_model_hf()\n",
        "    model = CustomModel(model_hf)\n",
        "    model = model.to(device)\n",
        "\n",
        "    if SEQUENTIAL_ASYNCHRONOUS_MTL == []:\n",
        "        optimizer = load_optimizer(model)\n",
        "        trainer = setup_trainer(model, train_dataset, val_dataset, optimizer, fold_counter)\n",
        "        trainer.train()\n",
        "    else:\n",
        "        for alphas in SEQUENTIAL_ASYNCHRONOUS_MTL:\n",
        "            ALPHA_TYPE, ALPHA_POLARITY, ALPHA_INTENSITY = alphas\n",
        "            print('Alphas:', alphas)\n",
        "            optimizer = load_optimizer(model)\n",
        "            trainer = setup_trainer(model, train_dataset, val_dataset, optimizer, fold_counter)\n",
        "            trainer.train()\n",
        "\n",
        "\n",
        "    train_results = trainer.evaluate(train_dataset)\n",
        "    val_results  = trainer.evaluate(val_dataset)\n",
        "    test_results = trainer.evaluate(test_dataset)\n",
        "\n",
        "    folds_train_log.append(train_results)\n",
        "    folds_val_log.append(val_results)\n",
        "    folds_test_log.append(test_results)\n",
        "    print(\"train_results =\",          train_results)\n",
        "    print(\"val_results =\",            val_results)\n",
        "    print(\"test_results =\",           test_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6vXgpwu2J2bf",
      "metadata": {
        "id": "6vXgpwu2J2bf"
      },
      "outputs": [],
      "source": [
        "print(folds_train_log)\n",
        "print(folds_val_log)\n",
        "print(folds_test_log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "j5lk3DzPJ2bf",
      "metadata": {
        "id": "j5lk3DzPJ2bf"
      },
      "outputs": [],
      "source": [
        "def print_log(folds_log, portion):\n",
        "    if portion == 'Train':\n",
        "        color = '\\033[1;31m'\n",
        "    elif portion == 'Validation':\n",
        "        color = '\\033[1;32m'\n",
        "    elif portion == 'Test':\n",
        "        color = '\\033[1;36m'\n",
        "\n",
        "    ignored_metrics = ['eval_runtime', 'eval_samples_per_second', 'eval_steps_per_second']\n",
        "    highlighted_metrics = ['eval_type_micro_f1', 'eval_polarity_accuracy', 'eval_intensity_accuracy', 'eval_average_of_metrics']\n",
        "\n",
        "    print(f'{color}{portion}:\\033[0m')\n",
        "    print(f'\\033[1mBased on steps with best {METRIC_FOR_BEST_MODEL}\\033[0m')\n",
        "\n",
        "    for metric_name in folds_log[0].keys():\n",
        "        if metric_name in ignored_metrics:\n",
        "            continue\n",
        "        metric_values_in_each_fold = np.round([fold_log[metric_name] for fold_log in folds_log], 6)\n",
        "        average = np.round(np.mean(metric_values_in_each_fold, axis=0), 6)\n",
        "        print()\n",
        "        if str(type(average)) == \"<class 'numpy.ndarray'>\":\n",
        "            print(f'\\033[1maverage {metric_name} of each type class:\\033[0m {average}')\n",
        "        elif metric_name in highlighted_metrics:\n",
        "            print(f'\\033[1m{metric_name}:\\033[0m {metric_values_in_each_fold}')\n",
        "            print(f'\\033[1maverage:\\033[0m {color}{average}\\033[0m')\n",
        "        else:\n",
        "            print(f'\\033[1m{metric_name}:\\033[0m {metric_values_in_each_fold}')\n",
        "            print(f'\\033[1maverage:\\033[0m {average}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "unugBZ_1aVqe",
      "metadata": {
        "id": "unugBZ_1aVqe"
      },
      "outputs": [],
      "source": [
        "print_log(folds_train_log, 'Train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LLbvbz9pgajZ",
      "metadata": {
        "id": "LLbvbz9pgajZ"
      },
      "outputs": [],
      "source": [
        "print_log(folds_val_log, 'Validation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ElfTO1c3Enmi",
      "metadata": {
        "id": "ElfTO1c3Enmi"
      },
      "outputs": [],
      "source": [
        "print_log(folds_test_log, 'Test')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oOzPfkUAJ2bi",
      "metadata": {
        "id": "oOzPfkUAJ2bi"
      },
      "source": [
        "# What's wrong?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MpiRL3zTJ2bg",
      "metadata": {
        "id": "MpiRL3zTJ2bg"
      },
      "outputs": [],
      "source": [
        "if SHOW_WRONG_PREDICTIONS == True or SHOW_ALL_PREDICTIONS == True:\n",
        "    pred = trainer.predict(val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HgqUPl1BJ2bg",
      "metadata": {
        "id": "HgqUPl1BJ2bg"
      },
      "outputs": [],
      "source": [
        "if SHOW_WRONG_PREDICTIONS == True or SHOW_ALL_PREDICTIONS == True:\n",
        "    targets = np.array(pred.label_ids, dtype=int)\n",
        "    preds = sigmoid(pred.predictions)\n",
        "    preds = np.array(preds > TYPE_THRESHOLD, dtype=int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tGJRde13J2bi",
      "metadata": {
        "id": "tGJRde13J2bi"
      },
      "outputs": [],
      "source": [
        "print('CLASSES:', TYPE_CLASSES)\n",
        "\n",
        "def classids2classnames(array):\n",
        "    res = []\n",
        "    for i in range(len(array)):\n",
        "        if array[i]:\n",
        "            res += [TYPE_CLASSES[i]]\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QyqPeQnvJ2bi",
      "metadata": {
        "id": "QyqPeQnvJ2bi"
      },
      "outputs": [],
      "source": [
        "if SHOW_WRONG_PREDICTIONS == True or SHOW_ALL_PREDICTIONS == True:\n",
        "    %mkdir results\n",
        "\n",
        "    file_postfix = 'all_predictions' if SHOW_ALL_PREDICTIONS == True else 'wrong_predictions'\n",
        "    with open(f'results/{EXPERIMENT_NAME}_{file_postfix}.txt', 'w') as f:\n",
        "\n",
        "        original_stdout = sys.stdout # Save a reference to the original standard output\n",
        "        sys.stdout = f # Change the standard output to the file we created.\n",
        "\n",
        "        CNT = 0\n",
        "        for i in range(len(preds)):\n",
        "            if SHOW_ALL_PREDICTIONS == True or not (preds[i][:NUM_TYPE_CLASSES] == targets[i][:NUM_TYPE_CLASSES]).all():\n",
        "                CNT += 1\n",
        "                print(f'\\n#{CNT}',\n",
        "                    f'\\nHead: {repr(X_val_head[i])}',\n",
        "                    f'\\nText: {repr(X_val_text[i])}',\n",
        "                    f'\\nPrediction:\\t {preds[i].tolist()} / {classids2classnames(preds[i][:NUM_TYPE_CLASSES].tolist())}',\n",
        "                    f'\\nTarget:\\t\\t {targets[i].tolist()} / {classids2classnames(targets[i][:NUM_TYPE_CLASSES].tolist())}')\n",
        "\n",
        "        sys.stdout = original_stdout # Reset the standard output to its original value"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pK5AmBQa4sg8",
      "metadata": {
        "id": "pK5AmBQa4sg8"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B7_EGzBemWws",
      "metadata": {
        "id": "B7_EGzBemWws"
      },
      "outputs": [],
      "source": [
        "if STORE_RESULTS != []:\n",
        "    %mkdir results\n",
        "\n",
        "    if not os.path.exists('results/results.txt'):\n",
        "        with open(f'results/results.txt', 'w') as f:\n",
        "            original_stdout = sys.stdout # Save a reference to the original standard output\n",
        "            sys.stdout = f # Change the standard output to the file we created.\n",
        "\n",
        "            print('Experiment Name \\t', end='')\n",
        "            for metric_name in STORE_RESULTS:\n",
        "                print(f'val {metric_name[5:].replace(\"_\", \" \").replace(\"type\", \"T\").replace(\"polarity\", \"P\").replace(\"intensity\", \"I\").replace(\"accuracy\", \"ACC\").replace(\"exact match ratio\", \"EMR\").replace(\"f1\", \"F1\").replace(\"micro \", \"\").replace(\"weighted\", \"\").replace(\"average of metrics\", \"AVG\")} \\t', end='')\n",
        "            for metric_name in STORE_RESULTS:\n",
        "                print(f'tst {metric_name[5:].replace(\"_\", \" \").replace(\"type\", \"T\").replace(\"polarity\", \"P\").replace(\"intensity\", \"I\").replace(\"accuracy\", \"ACC\").replace(\"exact match ratio\", \"EMR\").replace(\"f1\", \"F1\").replace(\"micro \", \"\").replace(\"weighted\", \"\").replace(\"average of metrics\", \"AVG\")} \\t', end='')\n",
        "            print(f'earlystopping \\t', end='')\n",
        "            print(f'epochs \\t', end='')\n",
        "            print()\n",
        "\n",
        "            sys.stdout = original_stdout # Reset the standard output to its original value\n",
        "\n",
        "    with open(f'results/results.txt', 'a') as f:\n",
        "        original_stdout = sys.stdout # Save a reference to the original standard output\n",
        "        sys.stdout = f # Change the standard output to the file we created.\n",
        "\n",
        "        print(f'{EXPERIMENT_NAME.replace(\".ipynb\", \"\").replace(\"_\", \" \")}: \\t', end='')\n",
        "\n",
        "        for metric_name in STORE_RESULTS:\n",
        "            if metric_name in folds_train_log[0]:\n",
        "                metric_values_in_each_fold = [fold_log[metric_name] for fold_log in folds_val_log]\n",
        "                average = np.round(np.mean(metric_values_in_each_fold, axis=0), 6)\n",
        "                print(f'{average} \\t', end='')\n",
        "            else:\n",
        "                print(f'- \\t\\t', end='')\n",
        "\n",
        "        for metric_name in STORE_RESULTS:\n",
        "            if metric_name in folds_train_log[0]:\n",
        "                metric_values_in_each_fold = [fold_log[metric_name] for fold_log in folds_test_log]\n",
        "                average = np.round(np.mean(metric_values_in_each_fold, axis=0), 6)\n",
        "                print(f'{average} \\t', end='')\n",
        "            else:\n",
        "                print(f'- \\t\\t', end='')\n",
        "\n",
        "        print(f'{np.round(EARLY_STOPPING*LOGGING_STEPS*TRAIN_BATCH_SIZE/n_train_samples, 2)} \\t\\t', end='')\n",
        "\n",
        "        epochs_in_each_fold = [fold_log['epoch'] for fold_log in folds_val_log]\n",
        "        average = np.round(np.mean(epochs_in_each_fold, axis=0), 2)\n",
        "        print(f'{average} \\t\\t', end='')\n",
        "\n",
        "        print()\n",
        "\n",
        "        sys.stdout = original_stdout # Reset the standard output to its original value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7jnbajtw4oL8",
      "metadata": {
        "id": "7jnbajtw4oL8"
      },
      "outputs": [],
      "source": [
        "print_log(folds_test_log, 'Test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VUPs8IH-4j5V",
      "metadata": {
        "id": "VUPs8IH-4j5V"
      },
      "outputs": [],
      "source": [
        "print_log(folds_val_log, 'Validation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0H5lJq1S2Nw0",
      "metadata": {
        "id": "0H5lJq1S2Nw0"
      },
      "outputs": [],
      "source": [
        "%rm -r models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oaHBIW8bf2F7",
      "metadata": {
        "id": "oaHBIW8bf2F7"
      },
      "source": [
        "# Timer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zznzDHU3Z8qO",
      "metadata": {
        "id": "zznzDHU3Z8qO"
      },
      "outputs": [],
      "source": [
        "# Time data\n",
        "\n",
        "end_time = datetime.now() # end timer\n",
        "\n",
        "print('\\033[1mStart:\\033[0m {}'.format(start_time))\n",
        "print('\\033[1mEnd:\\033[0m {}'.format(end_time))\n",
        "print('\\n\\033[1mDuration:\\033[0m {}'.format(end_time - start_time))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
